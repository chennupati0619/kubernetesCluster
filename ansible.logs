2020-05-31 17:13:09,283 p=24215 u=root n=ansible | PLAY [------------ | Kuberenetes Cluster Deployment | -------------------] ***********************************************************
2020-05-31 17:13:09,297 p=24215 u=root n=ansible | TASK [Gathering Facts] ***************************************************************************************************************
2020-05-31 17:13:11,007 p=24215 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:13:11,065 p=24215 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:13:11,094 p=24215 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:13:11,115 p=24215 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-05-31 17:13:11,182 p=24215 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:13:11,182 p=24215 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:13:11,209 p=24215 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:13:11,230 p=24215 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-05-31 17:13:11,758 p=24215 u=root n=ansible | changed: [node12.lab.example.com]
2020-05-31 17:13:11,762 p=24215 u=root n=ansible | changed: [node11.lab.example.com]
2020-05-31 17:13:11,771 p=24215 u=root n=ansible | changed: [nodea.lab.example.com]
2020-05-31 17:13:11,792 p=24215 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-05-31 17:13:11,869 p=24215 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:13:11,869 p=24215 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:13:11,894 p=24215 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:13:11,917 p=24215 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-05-31 17:13:12,927 p=24215 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:13:12,927 p=24215 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:13:12,933 p=24215 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:13:12,953 p=24215 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-05-31 17:13:13,450 p=24215 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:13:13,476 p=24215 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:13:13,476 p=24215 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:13:13,497 p=24215 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-05-31 17:13:13,577 p=24215 u=root n=ansible | fatal: [nodea.lab.example.com]: FAILED! => {"msg": "The conditional check 'KUBERNETES_MASTER in inventory_hostname' failed. The error was: Unexpected templating type error occurred on ({% if KUBERNETES_MASTER in inventory_hostname %} True {% else %} False {% endif %}): coercing to Unicode: need string or buffer, NoneType found\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 15, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: 3. Setting up firewall rules for master\n    ^ here\n"}
2020-05-31 17:13:13,578 p=24215 u=root n=ansible | fatal: [node11.lab.example.com]: FAILED! => {"msg": "The conditional check 'KUBERNETES_MASTER in inventory_hostname' failed. The error was: Unexpected templating type error occurred on ({% if KUBERNETES_MASTER in inventory_hostname %} True {% else %} False {% endif %}): coercing to Unicode: need string or buffer, NoneType found\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 15, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: 3. Setting up firewall rules for master\n    ^ here\n"}
2020-05-31 17:13:13,605 p=24215 u=root n=ansible | fatal: [node12.lab.example.com]: FAILED! => {"msg": "The conditional check 'KUBERNETES_MASTER in inventory_hostname' failed. The error was: Unexpected templating type error occurred on ({% if KUBERNETES_MASTER in inventory_hostname %} True {% else %} False {% endif %}): coercing to Unicode: need string or buffer, NoneType found\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 15, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: 3. Setting up firewall rules for master\n    ^ here\n"}
2020-05-31 17:13:13,606 p=24215 u=root n=ansible | PLAY RECAP ***************************************************************************************************************************
2020-05-31 17:13:13,607 p=24215 u=root n=ansible | node11.lab.example.com     : ok=4    changed=1    unreachable=0    failed=1    skipped=2    rescued=0    ignored=0   
2020-05-31 17:13:13,607 p=24215 u=root n=ansible | node12.lab.example.com     : ok=4    changed=1    unreachable=0    failed=1    skipped=2    rescued=0    ignored=0   
2020-05-31 17:13:13,607 p=24215 u=root n=ansible | nodea.lab.example.com      : ok=4    changed=1    unreachable=0    failed=1    skipped=2    rescued=0    ignored=0   
2020-05-31 17:13:56,571 p=24410 u=root n=ansible | PLAY [------------ | Kuberenetes Cluster Deployment | -------------------] ***********************************************************
2020-05-31 17:13:56,588 p=24410 u=root n=ansible | TASK [Gathering Facts] ***************************************************************************************************************
2020-05-31 17:13:57,902 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:13:57,958 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:13:58,010 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:13:58,030 p=24410 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-05-31 17:13:58,093 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:13:58,100 p=24410 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:13:58,140 p=24410 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:13:58,161 p=24410 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-05-31 17:13:58,752 p=24410 u=root n=ansible | changed: [node12.lab.example.com]
2020-05-31 17:13:58,788 p=24410 u=root n=ansible | changed: [node11.lab.example.com]
2020-05-31 17:13:58,789 p=24410 u=root n=ansible | changed: [nodea.lab.example.com]
2020-05-31 17:13:58,809 p=24410 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-05-31 17:13:58,880 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:13:58,881 p=24410 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:13:58,906 p=24410 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:13:58,929 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-05-31 17:13:59,872 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:13:59,875 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:13:59,878 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:13:59,899 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-05-31 17:14:00,471 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:14:00,505 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:14:00,511 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:00,534 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-05-31 17:14:00,629 p=24410 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-05-31 17:14:00,630 p=24410 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-05-31 17:14:00,630 p=24410 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-05-31 17:14:00,641 p=24410 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-05-31 17:14:00,659 p=24410 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-05-31 17:14:00,688 p=24410 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-05-31 17:14:00,696 p=24410 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-05-31 17:14:00,696 p=24410 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-05-31 17:14:00,697 p=24410 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-05-31 17:14:00,697 p=24410 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-05-31 17:14:01,257 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6443)
2020-05-31 17:14:01,734 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=2379-2380)
2020-05-31 17:14:02,206 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-05-31 17:14:02,697 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10251)
2020-05-31 17:14:03,174 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10252)
2020-05-31 17:14:03,196 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-05-31 17:14:03,274 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-05-31 17:14:03,275 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10255) 
2020-05-31 17:14:03,275 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=30000-32767) 
2020-05-31 17:14:03,276 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6783) 
2020-05-31 17:14:03,798 p=24410 u=root n=ansible | ok: [node11.lab.example.com] => (item=10250)
2020-05-31 17:14:03,836 p=24410 u=root n=ansible | ok: [node12.lab.example.com] => (item=10250)
2020-05-31 17:14:04,335 p=24410 u=root n=ansible | ok: [node11.lab.example.com] => (item=10255)
2020-05-31 17:14:04,386 p=24410 u=root n=ansible | ok: [node12.lab.example.com] => (item=10255)
2020-05-31 17:14:04,840 p=24410 u=root n=ansible | ok: [node11.lab.example.com] => (item=30000-32767)
2020-05-31 17:14:04,887 p=24410 u=root n=ansible | ok: [node12.lab.example.com] => (item=30000-32767)
2020-05-31 17:14:05,341 p=24410 u=root n=ansible | ok: [node11.lab.example.com] => (item=6783)
2020-05-31 17:14:05,396 p=24410 u=root n=ansible | ok: [node12.lab.example.com] => (item=6783)
2020-05-31 17:14:05,417 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-05-31 17:14:05,830 p=24410 u=root n=ansible | changed: [nodea.lab.example.com]
2020-05-31 17:14:05,853 p=24410 u=root n=ansible | changed: [node11.lab.example.com]
2020-05-31 17:14:05,869 p=24410 u=root n=ansible | changed: [node12.lab.example.com]
2020-05-31 17:14:05,890 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-05-31 17:14:05,962 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:14:05,964 p=24410 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:14:05,992 p=24410 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:14:06,013 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables] **************************************************************************
2020-05-31 17:14:06,734 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:06,803 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:14:06,818 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:14:06,839 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-05-31 17:14:07,267 p=24410 u=root n=ansible | changed: [nodea.lab.example.com]
2020-05-31 17:14:07,309 p=24410 u=root n=ansible | changed: [node11.lab.example.com]
2020-05-31 17:14:07,361 p=24410 u=root n=ansible | changed: [node12.lab.example.com]
2020-05-31 17:14:07,382 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-05-31 17:14:08,013 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:08,041 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:14:08,084 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:14:08,105 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required || Kubernetes || packages] *********************************************************
2020-05-31 17:14:10,305 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:10,315 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:14:10,322 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:14:10,345 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker,kubelet| service] *********************************************************************
2020-05-31 17:14:11,200 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=docker)
2020-05-31 17:14:11,236 p=24410 u=root n=ansible | ok: [node11.lab.example.com] => (item=docker)
2020-05-31 17:14:11,264 p=24410 u=root n=ansible | ok: [node12.lab.example.com] => (item=docker)
2020-05-31 17:14:11,670 p=24410 u=root n=ansible | ok: [nodea.lab.example.com] => (item=kubelet)
2020-05-31 17:14:11,749 p=24410 u=root n=ansible | ok: [node11.lab.example.com] => (item=kubelet)
2020-05-31 17:14:11,764 p=24410 u=root n=ansible | ok: [node12.lab.example.com] => (item=kubelet)
2020-05-31 17:14:11,789 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] *****************************************************
2020-05-31 17:14:12,255 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:12,265 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:14:12,315 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:14:12,336 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 13. ------------------------ | Master Setup | ----------------------] **************************************
2020-05-31 17:14:12,409 p=24410 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:14:12,439 p=24410 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:14:12,464 p=24410 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-master-setup.yml for nodea.lab.example.com
2020-05-31 17:14:12,494 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] *****************************************************************
2020-05-31 17:14:12,535 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:14:12,556 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ****************************************************************
2020-05-31 17:14:12,601 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=mkdir -p /root/.kube) 
2020-05-31 17:14:12,606 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf /root/.kube/config) 
2020-05-31 17:14:12,611 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=chown root:root /root/.kube/config) 
2020-05-31 17:14:12,634 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *******************************************************************************
2020-05-31 17:14:12,963 p=24410 u=root n=ansible | changed: [nodea.lab.example.com]
2020-05-31 17:14:12,984 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] *****************************************************************
2020-05-31 17:14:13,028 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:13,053 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 14. ------------------------ | Nodes/Worker Setup | ----------------] **************************************
2020-05-31 17:14:13,137 p=24410 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-05-31 17:14:13,263 p=24410 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml for node11.lab.example.com, node12.lab.example.com
2020-05-31 17:14:13,293 p=24410 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] *************************************************************
2020-05-31 17:14:13,619 p=24410 u=root n=ansible | ok: [node11.lab.example.com]
2020-05-31 17:14:13,645 p=24410 u=root n=ansible | ok: [node12.lab.example.com]
2020-05-31 17:14:13,667 p=24410 u=root n=ansible | TASK [Post-Requisite Configuring |weave| network] ************************************************************************************
2020-05-31 17:14:13,793 p=24410 u=root n=ansible | skipping: [node11.lab.example.com]
2020-05-31 17:14:13,843 p=24410 u=root n=ansible | skipping: [node12.lab.example.com]
2020-05-31 17:14:14,017 p=24410 u=root n=ansible | ok: [nodea.lab.example.com]
2020-05-31 17:14:14,019 p=24410 u=root n=ansible | PLAY RECAP ***************************************************************************************************************************
2020-05-31 17:14:14,019 p=24410 u=root n=ansible | node11.lab.example.com     : ok=14   changed=3    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-05-31 17:14:14,020 p=24410 u=root n=ansible | node12.lab.example.com     : ok=14   changed=3    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-05-31 17:14:14,020 p=24410 u=root n=ansible | nodea.lab.example.com      : ok=16   changed=4    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-06-01 02:18:25,006 p=1808 u=root n=ansible | PLAY [------------ | Kuberenetes Cluster Deployment | -------------------] **********************************************************
2020-06-01 02:18:25,224 p=1808 u=root n=ansible | TASK [Gathering Facts] **************************************************************************************************************
2020-06-01 02:18:28,288 p=1808 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:18:28,588 p=1808 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:18:28,764 p=1808 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:18:28,792 p=1808 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-06-01 02:18:29,464 p=1808 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:18:29,466 p=1808 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:18:29,481 p=1808 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:18:29,493 p=1808 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-06-01 02:18:29,859 p=1808 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:18:29,907 p=1808 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:18:29,913 p=1808 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:18:29,925 p=1808 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-06-01 02:18:30,335 p=1808 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:18:30,370 p=1808 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:18:30,371 p=1808 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:18:30,385 p=1808 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-06-01 02:18:31,356 p=1808 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:18:31,368 p=1808 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:18:31,403 p=1808 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:18:31,416 p=1808 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-06-01 02:18:31,969 p=1808 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:18:31,978 p=1808 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:18:31,978 p=1808 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:18:31,991 p=1808 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-06-01 02:18:32,071 p=1808 u=root n=ansible | fatal: [node11.lab.example.com]: FAILED! => {"msg": "The conditional check 'KUBERNETES_MASTER in inventory_hostname' failed. The error was: Unexpected templating type error occurred on ({% if KUBERNETES_MASTER in inventory_hostname %} True {% else %} False {% endif %}): coercing to Unicode: need string or buffer, NoneType found\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 12, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: 3. Setting up firewall rules for master\n    ^ here\n"}
2020-06-01 02:18:32,074 p=1808 u=root n=ansible | fatal: [nodea.lab.example.com]: FAILED! => {"msg": "The conditional check 'KUBERNETES_MASTER in inventory_hostname' failed. The error was: Unexpected templating type error occurred on ({% if KUBERNETES_MASTER in inventory_hostname %} True {% else %} False {% endif %}): coercing to Unicode: need string or buffer, NoneType found\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 12, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: 3. Setting up firewall rules for master\n    ^ here\n"}
2020-06-01 02:18:32,076 p=1808 u=root n=ansible | fatal: [node12.lab.example.com]: FAILED! => {"msg": "The conditional check 'KUBERNETES_MASTER in inventory_hostname' failed. The error was: Unexpected templating type error occurred on ({% if KUBERNETES_MASTER in inventory_hostname %} True {% else %} False {% endif %}): coercing to Unicode: need string or buffer, NoneType found\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 12, column 5, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n  - name: 3. Setting up firewall rules for master\n    ^ here\n"}
2020-06-01 02:18:32,077 p=1808 u=root n=ansible | PLAY RECAP **************************************************************************************************************************
2020-06-01 02:18:32,078 p=1808 u=root n=ansible | node11.lab.example.com     : ok=6    changed=5    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2020-06-01 02:18:32,078 p=1808 u=root n=ansible | node12.lab.example.com     : ok=6    changed=5    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2020-06-01 02:18:32,078 p=1808 u=root n=ansible | nodea.lab.example.com      : ok=6    changed=5    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2020-06-01 02:18:52,255 p=2022 u=root n=ansible | PLAY [------------ | Kuberenetes Cluster Deployment | -------------------] **********************************************************
2020-06-01 02:18:52,268 p=2022 u=root n=ansible | TASK [Gathering Facts] **************************************************************************************************************
2020-06-01 02:18:53,380 p=2022 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:18:53,417 p=2022 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:18:53,423 p=2022 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:18:53,436 p=2022 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-06-01 02:18:53,479 p=2022 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:18:53,499 p=2022 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:18:53,514 p=2022 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:18:53,526 p=2022 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-06-01 02:18:54,045 p=2022 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:18:54,063 p=2022 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:18:54,065 p=2022 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:18:54,077 p=2022 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-06-01 02:18:54,124 p=2022 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:18:54,140 p=2022 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:18:54,162 p=2022 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:18:54,175 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-06-01 02:18:55,174 p=2022 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:18:55,177 p=2022 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:18:55,183 p=2022 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:18:55,195 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-06-01 02:18:55,737 p=2022 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:18:55,742 p=2022 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:18:55,747 p=2022 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:18:55,760 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-06-01 02:18:55,943 p=2022 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-06-01 02:18:55,944 p=2022 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-06-01 02:18:55,944 p=2022 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-06-01 02:18:55,945 p=2022 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-06-01 02:18:55,945 p=2022 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-06-01 02:18:55,962 p=2022 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-06-01 02:18:55,962 p=2022 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-06-01 02:18:55,962 p=2022 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-06-01 02:18:55,966 p=2022 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-06-01 02:18:55,967 p=2022 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-06-01 02:18:56,524 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=6443)
2020-06-01 02:18:57,035 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=2379-2380)
2020-06-01 02:18:57,525 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10250)
2020-06-01 02:18:58,019 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10251)
2020-06-01 02:18:58,524 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10252)
2020-06-01 02:18:58,540 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] *****************************************************************
2020-06-01 02:18:58,592 p=2022 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-06-01 02:18:58,594 p=2022 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10255) 
2020-06-01 02:18:58,594 p=2022 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=30000-32767) 
2020-06-01 02:18:58,595 p=2022 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6783) 
2020-06-01 02:18:59,153 p=2022 u=root n=ansible | changed: [node11.lab.example.com] => (item=10250)
2020-06-01 02:18:59,204 p=2022 u=root n=ansible | changed: [node12.lab.example.com] => (item=10250)
2020-06-01 02:18:59,698 p=2022 u=root n=ansible | changed: [node11.lab.example.com] => (item=10255)
2020-06-01 02:18:59,724 p=2022 u=root n=ansible | changed: [node12.lab.example.com] => (item=10255)
2020-06-01 02:19:00,217 p=2022 u=root n=ansible | changed: [node11.lab.example.com] => (item=30000-32767)
2020-06-01 02:19:00,285 p=2022 u=root n=ansible | changed: [node12.lab.example.com] => (item=30000-32767)
2020-06-01 02:19:00,762 p=2022 u=root n=ansible | changed: [node11.lab.example.com] => (item=6783)
2020-06-01 02:19:00,792 p=2022 u=root n=ansible | changed: [node12.lab.example.com] => (item=6783)
2020-06-01 02:19:00,806 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] *****************************************************************************
2020-06-01 02:19:01,151 p=2022 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:19:01,159 p=2022 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:19:01,166 p=2022 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:19:01,178 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ********************************************************************
2020-06-01 02:19:01,600 p=2022 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:19:01,618 p=2022 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:19:01,625 p=2022 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:19:01,639 p=2022 u=root n=ansible | TASK [deploy_kubernetes : Setting sysctl rules] *************************************************************************************
2020-06-01 02:19:02,237 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:19:02,260 p=2022 u=root n=ansible | changed: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:19:02,269 p=2022 u=root n=ansible | changed: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:19:02,580 p=2022 u=root n=ansible | changed: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:19:02,590 p=2022 u=root n=ansible | changed: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:19:02,600 p=2022 u=root n=ansible | changed: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:19:02,614 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] *************************************************************
2020-06-01 02:19:03,427 p=2022 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:19:03,446 p=2022 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:19:03,453 p=2022 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:19:03,479 p=2022 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required || Kubernetes || packages] ********************************************************
2020-06-01 02:20:07,200 p=2022 u=root n=ansible | fatal: [nodea.lab.example.com]: FAILED! => {"changed": false, "msg": "Failure talking to yum: Cannot find a valid baseurl for repo: base/7/x86_64"}
2020-06-01 02:20:07,311 p=2022 u=root n=ansible | fatal: [node11.lab.example.com]: FAILED! => {"changed": false, "msg": "Failure talking to yum: Cannot find a valid baseurl for repo: base/7/x86_64"}
2020-06-01 02:20:07,671 p=2022 u=root n=ansible | fatal: [node12.lab.example.com]: FAILED! => {"changed": false, "msg": "Failure talking to yum: Cannot find a valid baseurl for repo: base/7/x86_64"}
2020-06-01 02:20:07,673 p=2022 u=root n=ansible | PLAY RECAP **************************************************************************************************************************
2020-06-01 02:20:07,673 p=2022 u=root n=ansible | node11.lab.example.com     : ok=9    changed=6    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2020-06-01 02:20:07,673 p=2022 u=root n=ansible | node12.lab.example.com     : ok=9    changed=6    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2020-06-01 02:20:07,673 p=2022 u=root n=ansible | nodea.lab.example.com      : ok=9    changed=6    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2020-06-01 02:20:51,497 p=2458 u=root n=ansible | PLAY [------------ | Kuberenetes Cluster Deployment | -------------------] **********************************************************
2020-06-01 02:20:51,511 p=2458 u=root n=ansible | TASK [Gathering Facts] **************************************************************************************************************
2020-06-01 02:20:52,633 p=2458 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:20:52,669 p=2458 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:20:52,695 p=2458 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:20:52,707 p=2458 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-06-01 02:20:52,760 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:20:52,772 p=2458 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:20:52,785 p=2458 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:20:52,798 p=2458 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-06-01 02:20:53,367 p=2458 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:20:53,376 p=2458 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:20:53,378 p=2458 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:20:53,390 p=2458 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-06-01 02:20:53,436 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:20:53,457 p=2458 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:20:53,473 p=2458 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:20:53,486 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-06-01 02:20:54,402 p=2458 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:20:54,432 p=2458 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:20:54,436 p=2458 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:20:54,448 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-06-01 02:20:55,006 p=2458 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:20:55,012 p=2458 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:20:55,022 p=2458 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:20:55,037 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-06-01 02:20:55,189 p=2458 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-06-01 02:20:55,189 p=2458 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-06-01 02:20:55,190 p=2458 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-06-01 02:20:55,190 p=2458 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-06-01 02:20:55,191 p=2458 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-06-01 02:20:55,196 p=2458 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-06-01 02:20:55,203 p=2458 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-06-01 02:20:55,215 p=2458 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-06-01 02:20:55,215 p=2458 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-06-01 02:20:55,215 p=2458 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-06-01 02:20:55,755 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6443)
2020-06-01 02:20:56,218 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=2379-2380)
2020-06-01 02:20:56,688 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-06-01 02:20:57,174 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10251)
2020-06-01 02:20:57,644 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10252)
2020-06-01 02:20:57,657 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] *****************************************************************
2020-06-01 02:20:57,710 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-06-01 02:20:57,712 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10255) 
2020-06-01 02:20:57,713 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=30000-32767) 
2020-06-01 02:20:57,713 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6783) 
2020-06-01 02:20:58,236 p=2458 u=root n=ansible | ok: [node11.lab.example.com] => (item=10250)
2020-06-01 02:20:58,257 p=2458 u=root n=ansible | ok: [node12.lab.example.com] => (item=10250)
2020-06-01 02:20:58,756 p=2458 u=root n=ansible | ok: [node11.lab.example.com] => (item=10255)
2020-06-01 02:20:58,771 p=2458 u=root n=ansible | ok: [node12.lab.example.com] => (item=10255)
2020-06-01 02:20:59,262 p=2458 u=root n=ansible | ok: [node11.lab.example.com] => (item=30000-32767)
2020-06-01 02:20:59,282 p=2458 u=root n=ansible | ok: [node12.lab.example.com] => (item=30000-32767)
2020-06-01 02:20:59,747 p=2458 u=root n=ansible | ok: [node11.lab.example.com] => (item=6783)
2020-06-01 02:20:59,763 p=2458 u=root n=ansible | ok: [node12.lab.example.com] => (item=6783)
2020-06-01 02:20:59,777 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] *****************************************************************************
2020-06-01 02:21:00,123 p=2458 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:21:00,162 p=2458 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:21:00,176 p=2458 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:21:00,189 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ********************************************************************
2020-06-01 02:21:00,244 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:21:00,256 p=2458 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:21:00,273 p=2458 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:21:00,286 p=2458 u=root n=ansible | TASK [deploy_kubernetes : Setting sysctl rules] *************************************************************************************
2020-06-01 02:21:00,832 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:21:00,849 p=2458 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:21:00,898 p=2458 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:21:01,207 p=2458 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:21:01,239 p=2458 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:21:01,246 p=2458 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:21:01,259 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] *************************************************************
2020-06-01 02:21:01,898 p=2458 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:21:01,918 p=2458 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:21:01,925 p=2458 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:21:01,938 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required || Kubernetes || packages] ********************************************************
2020-06-01 02:26:11,203 p=2458 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:26:15,251 p=2458 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:26:17,634 p=2458 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:26:17,664 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker,kubelet| service] ********************************************************************
2020-06-01 02:26:21,086 p=2458 u=root n=ansible | changed: [nodea.lab.example.com] => (item=docker)
2020-06-01 02:26:21,143 p=2458 u=root n=ansible | changed: [node11.lab.example.com] => (item=docker)
2020-06-01 02:26:21,399 p=2458 u=root n=ansible | changed: [node12.lab.example.com] => (item=docker)
2020-06-01 02:26:22,010 p=2458 u=root n=ansible | changed: [nodea.lab.example.com] => (item=kubelet)
2020-06-01 02:26:22,131 p=2458 u=root n=ansible | changed: [node11.lab.example.com] => (item=kubelet)
2020-06-01 02:26:22,200 p=2458 u=root n=ansible | changed: [node12.lab.example.com] => (item=kubelet)
2020-06-01 02:26:22,218 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] ****************************************************
2020-06-01 02:26:22,643 p=2458 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:26:22,695 p=2458 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:26:22,721 p=2458 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:26:22,735 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 13. ------------------------ | Master Setup | ----------------------] *************************************
2020-06-01 02:26:22,805 p=2458 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:26:22,820 p=2458 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:26:22,861 p=2458 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-master-setup.yml for nodea.lab.example.com
2020-06-01 02:26:22,882 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] ****************************************************************
2020-06-01 02:30:30,953 p=2458 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:30:30,966 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ***************************************************************
2020-06-01 02:30:31,276 p=2458 u=root n=ansible | changed: [nodea.lab.example.com] => (item=mkdir -p /root/.kube)
2020-06-01 02:30:31,618 p=2458 u=root n=ansible | changed: [nodea.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf /root/.kube/config)
2020-06-01 02:30:31,909 p=2458 u=root n=ansible | changed: [nodea.lab.example.com] => (item=chown root:root /root/.kube/config)
2020-06-01 02:30:31,911 p=2458 u=root n=ansible | [WARNING]: Consider using the file module with state=directory rather than running 'mkdir'.  If you need to use command because file
is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this
message.

2020-06-01 02:30:31,911 p=2458 u=root n=ansible | [WARNING]: Consider using 'become', 'become_method', and 'become_user' rather than running sudo

2020-06-01 02:30:31,912 p=2458 u=root n=ansible | [WARNING]: Consider using the file module with owner rather than running 'chown'.  If you need to use command because file is
insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this
message.

2020-06-01 02:30:31,926 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] ******************************************************************************
2020-06-01 02:30:32,248 p=2458 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:30:32,277 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] ****************************************************************
2020-06-01 02:30:32,322 p=2458 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:30:32,335 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 14. ------------------------ | Nodes/Worker Setup | ----------------] *************************************
2020-06-01 02:30:32,391 p=2458 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:30:32,464 p=2458 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml for node11.lab.example.com, node12.lab.example.com
2020-06-01 02:30:32,489 p=2458 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] ************************************************************
2020-06-01 02:30:42,699 p=2458 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:30:42,704 p=2458 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:30:42,718 p=2458 u=root n=ansible | TASK [Post-Requisite Configuring |weave| network] ***********************************************************************************
2020-06-01 02:30:42,815 p=2458 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:30:42,843 p=2458 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:30:45,731 p=2458 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:30:45,734 p=2458 u=root n=ansible | PLAY RECAP **************************************************************************************************************************
2020-06-01 02:30:45,735 p=2458 u=root n=ansible | node11.lab.example.com     : ok=13   changed=5    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-06-01 02:30:45,735 p=2458 u=root n=ansible | node12.lab.example.com     : ok=13   changed=5    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-06-01 02:30:45,735 p=2458 u=root n=ansible | nodea.lab.example.com      : ok=17   changed=8    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2020-06-01 02:31:58,488 p=3032 u=root n=ansible | PLAY [------------ | Kuberenetes Cluster Deployment | -------------------] *********************************************************
2020-06-01 02:31:58,507 p=3032 u=root n=ansible | TASK [Gathering Facts] *************************************************************************************************************
2020-06-01 02:32:00,328 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:00,362 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:00,410 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:00,425 p=3032 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ****************************************************************************************
2020-06-01 02:32:00,506 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:32:00,510 p=3032 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:32:00,510 p=3032 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:32:00,525 p=3032 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] **********************************************************************************
2020-06-01 02:32:01,094 p=3032 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:32:01,113 p=3032 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:32:01,118 p=3032 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:32:01,132 p=3032 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] *************************************************************************************
2020-06-01 02:32:01,201 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:32:01,217 p=3032 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:32:01,233 p=3032 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:32:01,249 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ************************************************************************
2020-06-01 02:32:02,253 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:02,262 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:02,269 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:02,283 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ***************************************************************************
2020-06-01 02:32:02,949 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:02,974 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:02,982 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:02,999 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *****************************************************************
2020-06-01 02:32:03,112 p=3032 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-06-01 02:32:03,112 p=3032 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-06-01 02:32:03,113 p=3032 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-06-01 02:32:03,114 p=3032 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-06-01 02:32:03,114 p=3032 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-06-01 02:32:03,127 p=3032 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-06-01 02:32:03,127 p=3032 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-06-01 02:32:03,131 p=3032 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-06-01 02:32:03,135 p=3032 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-06-01 02:32:03,140 p=3032 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-06-01 02:32:03,792 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6443)
2020-06-01 02:32:04,336 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=2379-2380)
2020-06-01 02:32:04,897 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-06-01 02:32:05,439 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10251)
2020-06-01 02:32:05,985 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10252)
2020-06-01 02:32:06,000 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ****************************************************************
2020-06-01 02:32:06,096 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-06-01 02:32:06,096 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10255) 
2020-06-01 02:32:06,097 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=30000-32767) 
2020-06-01 02:32:06,105 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6783) 
2020-06-01 02:32:06,714 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=10250)
2020-06-01 02:32:06,714 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=10250)
2020-06-01 02:32:07,293 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=10255)
2020-06-01 02:32:07,294 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=10255)
2020-06-01 02:32:07,868 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=30000-32767)
2020-06-01 02:32:07,893 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=30000-32767)
2020-06-01 02:32:08,480 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=6783)
2020-06-01 02:32:08,512 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=6783)
2020-06-01 02:32:08,532 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ****************************************************************************
2020-06-01 02:32:09,011 p=3032 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:32:09,048 p=3032 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 02:32:09,060 p=3032 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 02:32:09,076 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *******************************************************************
2020-06-01 02:32:09,148 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:32:09,161 p=3032 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:32:09,179 p=3032 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:32:09,195 p=3032 u=root n=ansible | TASK [deploy_kubernetes : Setting sysctl rules] ************************************************************************************
2020-06-01 02:32:09,865 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:32:09,887 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:32:09,937 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 02:32:10,357 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:32:10,451 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:32:10,463 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 02:32:10,481 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ************************************************************
2020-06-01 02:32:11,284 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:11,325 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:11,373 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:11,388 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required || Kubernetes || packages] *******************************************************
2020-06-01 02:32:17,526 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:17,789 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:17,890 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:17,906 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker,kubelet| service] *******************************************************************
2020-06-01 02:32:18,853 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=docker)
2020-06-01 02:32:18,872 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=docker)
2020-06-01 02:32:18,874 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=docker)
2020-06-01 02:32:19,391 p=3032 u=root n=ansible | ok: [node12.lab.example.com] => (item=kubelet)
2020-06-01 02:32:19,397 p=3032 u=root n=ansible | ok: [nodea.lab.example.com] => (item=kubelet)
2020-06-01 02:32:19,400 p=3032 u=root n=ansible | ok: [node11.lab.example.com] => (item=kubelet)
2020-06-01 02:32:19,422 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] ***************************************************
2020-06-01 02:32:19,905 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:19,917 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:19,939 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:19,955 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 13. ------------------------ | Master Setup | ----------------------] ************************************
2020-06-01 02:32:20,040 p=3032 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:32:20,045 p=3032 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:32:20,064 p=3032 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-master-setup.yml for nodea.lab.example.com
2020-06-01 02:32:20,088 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] ***************************************************************
2020-06-01 02:32:20,130 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:32:20,145 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] **************************************************************
2020-06-01 02:32:20,194 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=mkdir -p /root/.kube) 
2020-06-01 02:32:20,198 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf /root/.kube/config) 
2020-06-01 02:32:20,203 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=chown root:root /root/.kube/config) 
2020-06-01 02:32:20,224 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *****************************************************************************
2020-06-01 02:32:20,576 p=3032 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 02:32:20,592 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] ***************************************************************
2020-06-01 02:32:20,642 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:20,657 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 14. ------------------------ | Nodes/Worker Setup | ----------------] ************************************
2020-06-01 02:32:20,728 p=3032 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 02:32:20,786 p=3032 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml for node11.lab.example.com, node12.lab.example.com
2020-06-01 02:32:20,814 p=3032 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] ***********************************************************
2020-06-01 02:32:21,161 p=3032 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 02:32:21,191 p=3032 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 02:32:21,207 p=3032 u=root n=ansible | TASK [Post-Requisite Configuring |weave| network] **********************************************************************************
2020-06-01 02:32:21,311 p=3032 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 02:32:21,315 p=3032 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 02:32:21,536 p=3032 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 02:32:21,538 p=3032 u=root n=ansible | PLAY RECAP *************************************************************************************************************************
2020-06-01 02:32:21,539 p=3032 u=root n=ansible | node11.lab.example.com     : ok=13   changed=2    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-06-01 02:32:21,539 p=3032 u=root n=ansible | node12.lab.example.com     : ok=13   changed=2    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-06-01 02:32:21,539 p=3032 u=root n=ansible | nodea.lab.example.com      : ok=15   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-06-01 03:08:04,961 p=3884 u=root n=ansible | ERROR! this task 'msg' has extra params, which is only allowed in the following modules: shell, win_shell, include_vars, add_host, raw, include_role, meta, set_fact, include, import_tasks, script, import_role, include_tasks, group_by, command, win_command

The error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/main.yml': line 2, column 5, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
  - name: 0. Starting with role deployment
    ^ here

2020-06-01 03:09:07,675 p=3894 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] **********************************
2020-06-01 03:09:07,691 p=3894 u=root n=ansible | TASK [Gathering Facts] *************************************************************************************************************
2020-06-01 03:09:09,348 p=3894 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:09:09,445 p=3894 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:09,725 p=3894 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:09,746 p=3894 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ****************************************************************************************
2020-06-01 03:09:09,812 p=3894 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:09:09,813 p=3894 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:09:09,842 p=3894 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:09:09,865 p=3894 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] **********************************************************************************
2020-06-01 03:09:10,420 p=3894 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:09:10,443 p=3894 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:09:10,443 p=3894 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:09:10,464 p=3894 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] *************************************************************************************
2020-06-01 03:09:10,562 p=3894 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:09:10,593 p=3894 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:09:10,616 p=3894 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:09:10,651 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] ************************************************************************
2020-06-01 03:09:10,681 p=3894 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:09:10,717 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:09:10,762 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:09:10,782 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ************************************************************************
2020-06-01 03:09:11,709 p=3894 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:09:11,716 p=3894 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:11,724 p=3894 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:11,746 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ***************************************************************************
2020-06-01 03:09:12,257 p=3894 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:12,262 p=3894 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:12,270 p=3894 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:09:12,291 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *****************************************************************
2020-06-01 03:09:12,388 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-06-01 03:09:12,389 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-06-01 03:09:12,404 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-06-01 03:09:12,405 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-06-01 03:09:12,405 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-06-01 03:09:12,405 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=80) 
2020-06-01 03:09:12,406 p=3894 u=root n=ansible | skipping: [node11.lab.example.com] => (item=8080) 
2020-06-01 03:09:12,417 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-06-01 03:09:12,418 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-06-01 03:09:12,419 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-06-01 03:09:12,423 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-06-01 03:09:12,427 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-06-01 03:09:12,432 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=80) 
2020-06-01 03:09:12,443 p=3894 u=root n=ansible | skipping: [node12.lab.example.com] => (item=8080) 
2020-06-01 03:09:12,970 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=6443) => {"ansible_loop_var": "item", "changed": false, "item": 6443, "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:13,400 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=2379-2380) => {"ansible_loop_var": "item", "changed": false, "item": "2379-2380", "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:13,831 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=10250) => {"ansible_loop_var": "item", "changed": false, "item": 10250, "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:14,268 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=10251) => {"ansible_loop_var": "item", "changed": false, "item": 10251, "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:14,694 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=10252) => {"ansible_loop_var": "item", "changed": false, "item": 10252, "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:15,124 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=80) => {"ansible_loop_var": "item", "changed": false, "item": 80, "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:15,552 p=3894 u=root n=ansible | failed: [nodea.lab.example.com] (item=8080) => {"ansible_loop_var": "item", "changed": false, "item": 8080, "msg": "firewall is not currently running, unable to perform immediate actions without a running firewall daemon"}
2020-06-01 03:09:15,576 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ****************************************************************
2020-06-01 03:09:16,139 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=10250)
2020-06-01 03:09:16,188 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=10250)
2020-06-01 03:09:16,684 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=10255)
2020-06-01 03:09:16,704 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=10255)
2020-06-01 03:09:17,223 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=30000-32767)
2020-06-01 03:09:17,240 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=30000-32767)
2020-06-01 03:09:17,747 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=6783)
2020-06-01 03:09:17,756 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=6783)
2020-06-01 03:09:18,303 p=3894 u=root n=ansible | changed: [node11.lab.example.com] => (item=80)
2020-06-01 03:09:18,349 p=3894 u=root n=ansible | changed: [node12.lab.example.com] => (item=80)
2020-06-01 03:09:18,843 p=3894 u=root n=ansible | changed: [node11.lab.example.com] => (item=8080)
2020-06-01 03:09:18,884 p=3894 u=root n=ansible | changed: [node12.lab.example.com] => (item=8080)
2020-06-01 03:09:18,906 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ****************************************************************************
2020-06-01 03:09:19,192 p=3894 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:09:19,239 p=3894 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:09:19,260 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *******************************************************************
2020-06-01 03:09:19,300 p=3894 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:09:19,335 p=3894 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:09:19,356 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ***********************************************************
2020-06-01 03:09:19,841 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:09:19,859 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:09:20,136 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:09:20,147 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:09:20,171 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] *************************************************************
2020-06-01 03:09:20,456 p=3894 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:09:20,478 p=3894 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:09:20,499 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ************************************************************
2020-06-01 03:09:20,996 p=3894 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:21,017 p=3894 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:21,038 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] *********************************************************
2020-06-01 03:09:23,980 p=3894 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:26,123 p=3894 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:26,143 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *****************************************************************
2020-06-01 03:09:26,879 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=docker)
2020-06-01 03:09:26,895 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=docker)
2020-06-01 03:09:27,229 p=3894 u=root n=ansible | ok: [node11.lab.example.com] => (item=kubelet)
2020-06-01 03:09:27,238 p=3894 u=root n=ansible | ok: [node12.lab.example.com] => (item=kubelet)
2020-06-01 03:09:27,262 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] ***************************************************
2020-06-01 03:09:27,552 p=3894 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:27,591 p=3894 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:27,612 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] **********************************
2020-06-01 03:09:27,651 p=3894 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:09:27,679 p=3894 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:09:27,702 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] **********************************
2020-06-01 03:09:27,812 p=3894 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml for node11.lab.example.com, node12.lab.example.com
2020-06-01 03:09:27,839 p=3894 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] ***********************************************************
2020-06-01 03:09:27,894 p=3894 u=root n=ansible | fatal: [node11.lab.example.com]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'kubernetes_join_workers'\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml': line 2, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n---\n- name: 14.1 Joining Worker to | Kubernetes | cluster\n  ^ here\n"}
2020-06-01 03:09:27,929 p=3894 u=root n=ansible | fatal: [node12.lab.example.com]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'kubernetes_join_workers'\n\nThe error appears to be in '/tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml': line 2, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n---\n- name: 14.1 Joining Worker to | Kubernetes | cluster\n  ^ here\n"}
2020-06-01 03:09:27,930 p=3894 u=root n=ansible | PLAY RECAP *************************************************************************************************************************
2020-06-01 03:09:27,930 p=3894 u=root n=ansible | node11.lab.example.com     : ok=14   changed=4    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2020-06-01 03:09:27,930 p=3894 u=root n=ansible | node12.lab.example.com     : ok=14   changed=4    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2020-06-01 03:09:27,930 p=3894 u=root n=ansible | nodea.lab.example.com      : ok=5    changed=1    unreachable=0    failed=1    skipped=2    rescued=0    ignored=0   
2020-06-01 03:09:55,154 p=4378 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] **********************************
2020-06-01 03:09:55,170 p=4378 u=root n=ansible | TASK [Gathering Facts] *************************************************************************************************************
2020-06-01 03:09:56,566 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:09:56,580 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:56,614 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:56,634 p=4378 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ****************************************************************************************
2020-06-01 03:09:56,707 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:09:56,708 p=4378 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:09:56,737 p=4378 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:09:56,757 p=4378 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] **********************************************************************************
2020-06-01 03:09:57,368 p=4378 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:09:57,384 p=4378 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:09:57,400 p=4378 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:09:57,421 p=4378 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] *************************************************************************************
2020-06-01 03:09:57,492 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:09:57,492 p=4378 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:09:57,521 p=4378 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:09:57,542 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] ************************************************************************
2020-06-01 03:09:57,572 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:09:57,603 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:09:57,614 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:09:57,635 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ************************************************************************
2020-06-01 03:09:58,616 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:09:58,618 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:58,619 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:58,639 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ***************************************************************************
2020-06-01 03:09:59,172 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:09:59,186 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:09:59,198 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:09:59,220 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *****************************************************************
2020-06-01 03:09:59,329 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-06-01 03:09:59,330 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-06-01 03:09:59,330 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-06-01 03:09:59,330 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-06-01 03:09:59,335 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-06-01 03:09:59,335 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=80) 
2020-06-01 03:09:59,336 p=4378 u=root n=ansible | skipping: [node11.lab.example.com] => (item=8080) 
2020-06-01 03:09:59,344 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-06-01 03:09:59,353 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-06-01 03:09:59,375 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-06-01 03:09:59,376 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-06-01 03:09:59,376 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-06-01 03:09:59,377 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=80) 
2020-06-01 03:09:59,377 p=4378 u=root n=ansible | skipping: [node12.lab.example.com] => (item=8080) 
2020-06-01 03:09:59,936 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6443)
2020-06-01 03:10:00,424 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=2379-2380)
2020-06-01 03:10:00,897 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-06-01 03:10:01,376 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10251)
2020-06-01 03:10:01,861 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10252)
2020-06-01 03:10:02,391 p=4378 u=root n=ansible | changed: [nodea.lab.example.com] => (item=80)
2020-06-01 03:10:02,915 p=4378 u=root n=ansible | changed: [nodea.lab.example.com] => (item=8080)
2020-06-01 03:10:02,939 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ****************************************************************
2020-06-01 03:10:03,022 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-06-01 03:10:03,023 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10255) 
2020-06-01 03:10:03,024 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=30000-32767) 
2020-06-01 03:10:03,024 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6783) 
2020-06-01 03:10:03,024 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=80) 
2020-06-01 03:10:03,025 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=8080) 
2020-06-01 03:10:03,620 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=10250)
2020-06-01 03:10:03,640 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=10250)
2020-06-01 03:10:04,175 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=10255)
2020-06-01 03:10:04,241 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=10255)
2020-06-01 03:10:04,689 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=30000-32767)
2020-06-01 03:10:04,758 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=30000-32767)
2020-06-01 03:10:05,196 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=6783)
2020-06-01 03:10:05,242 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=6783)
2020-06-01 03:10:05,706 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=80)
2020-06-01 03:10:05,747 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=80)
2020-06-01 03:10:06,215 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=8080)
2020-06-01 03:10:06,267 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=8080)
2020-06-01 03:10:06,289 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ****************************************************************************
2020-06-01 03:10:06,701 p=4378 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:10:06,702 p=4378 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:10:06,740 p=4378 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:10:06,761 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *******************************************************************
2020-06-01 03:10:06,833 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:10:06,833 p=4378 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:10:06,863 p=4378 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:10:06,884 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ***********************************************************
2020-06-01 03:10:07,514 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:10:07,566 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:10:07,567 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:10:07,877 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:10:07,936 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:10:07,946 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:10:07,968 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] *************************************************************
2020-06-01 03:10:08,449 p=4378 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:10:08,470 p=4378 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:10:08,475 p=4378 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:10:08,497 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ************************************************************
2020-06-01 03:10:09,145 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:10:09,160 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:10:09,246 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:10:09,267 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] *********************************************************
2020-06-01 03:10:14,537 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:10:14,554 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:10:14,581 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:10:14,603 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *****************************************************************
2020-06-01 03:10:15,489 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=docker)
2020-06-01 03:10:15,522 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=docker)
2020-06-01 03:10:15,538 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=docker)
2020-06-01 03:10:15,934 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => (item=kubelet)
2020-06-01 03:10:15,988 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => (item=kubelet)
2020-06-01 03:10:16,008 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => (item=kubelet)
2020-06-01 03:10:16,032 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] ***************************************************
2020-06-01 03:10:16,500 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:10:16,508 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:10:16,512 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:10:16,533 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] **********************************
2020-06-01 03:10:16,613 p=4378 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:10:16,634 p=4378 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:10:16,659 p=4378 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-master-setup.yml for nodea.lab.example.com
2020-06-01 03:10:16,691 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] ***************************************************************
2020-06-01 03:10:16,728 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:10:16,750 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] **************************************************************
2020-06-01 03:10:16,794 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=mkdir -p ~/.kube) 
2020-06-01 03:10:16,798 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config) 
2020-06-01 03:10:16,801 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config) 
2020-06-01 03:10:16,823 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *****************************************************************************
2020-06-01 03:10:17,155 p=4378 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:10:17,176 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] ***************************************************************
2020-06-01 03:10:17,222 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:10:17,243 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] **********************************
2020-06-01 03:10:17,315 p=4378 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:10:17,391 p=4378 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml for node11.lab.example.com, node12.lab.example.com
2020-06-01 03:10:17,425 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] ***********************************************************
2020-06-01 03:10:17,759 p=4378 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:10:17,782 p=4378 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:10:17,807 p=4378 u=root n=ansible | TASK [deploy_kubernetes : 15. Ending with role deployment] *************************************************************************
2020-06-01 03:10:17,837 p=4378 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-06-01 03:10:17,868 p=4378 u=root n=ansible | ok: [node11.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-06-01 03:10:17,879 p=4378 u=root n=ansible | ok: [node12.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-06-01 03:10:17,902 p=4378 u=root n=ansible | TASK [Post-Requisite Configuring | weave | network] ********************************************************************************
2020-06-01 03:10:17,983 p=4378 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:10:18,008 p=4378 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:10:18,213 p=4378 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:10:18,215 p=4378 u=root n=ansible | PLAY RECAP *************************************************************************************************************************
2020-06-01 03:10:18,216 p=4378 u=root n=ansible | node11.lab.example.com     : ok=16   changed=3    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-06-01 03:10:18,216 p=4378 u=root n=ansible | node12.lab.example.com     : ok=16   changed=3    unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2020-06-01 03:10:18,216 p=4378 u=root n=ansible | nodea.lab.example.com      : ok=18   changed=5    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-06-01 03:12:40,214 p=4996 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] **********************************
2020-06-01 03:12:40,230 p=4996 u=root n=ansible | TASK [Gathering Facts] *************************************************************************************************************
2020-06-01 03:12:41,735 p=4996 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:12:41,819 p=4996 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:12:41,823 p=4996 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:12:41,836 p=4996 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ****************************************************************************************
2020-06-01 03:12:42,440 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:42,442 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:42,460 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:42,472 p=4996 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] **********************************************************************************
2020-06-01 03:12:42,851 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:42,857 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:42,916 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:42,931 p=4996 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] *************************************************************************************
2020-06-01 03:12:43,332 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:43,369 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:43,403 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:43,416 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] ************************************************************************
2020-06-01 03:12:43,436 p=4996 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:12:43,455 p=4996 u=root n=ansible | ok: [node11.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:12:43,466 p=4996 u=root n=ansible | ok: [node12.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-06-01 03:12:43,480 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ************************************************************************
2020-06-01 03:12:44,524 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:44,539 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:44,563 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:44,576 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] ***************************************************************************
2020-06-01 03:12:45,063 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:45,073 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:45,082 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:45,096 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *****************************************************************
2020-06-01 03:12:45,187 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=6443) 
2020-06-01 03:12:45,187 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=2379-2380) 
2020-06-01 03:12:45,188 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10250) 
2020-06-01 03:12:45,201 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10251) 
2020-06-01 03:12:45,201 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=10252) 
2020-06-01 03:12:45,202 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=80) 
2020-06-01 03:12:45,202 p=4996 u=root n=ansible | skipping: [node11.lab.example.com] => (item=8080) 
2020-06-01 03:12:45,206 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=6443) 
2020-06-01 03:12:45,206 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=2379-2380) 
2020-06-01 03:12:45,207 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10250) 
2020-06-01 03:12:45,207 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10251) 
2020-06-01 03:12:45,209 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=10252) 
2020-06-01 03:12:45,210 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=80) 
2020-06-01 03:12:45,219 p=4996 u=root n=ansible | skipping: [node12.lab.example.com] => (item=8080) 
2020-06-01 03:12:45,803 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=6443)
2020-06-01 03:12:46,306 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=2379-2380)
2020-06-01 03:12:46,800 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10250)
2020-06-01 03:12:47,283 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10251)
2020-06-01 03:12:47,790 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10252)
2020-06-01 03:12:48,278 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=80)
2020-06-01 03:12:48,767 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=8080)
2020-06-01 03:12:48,780 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ****************************************************************
2020-06-01 03:12:48,867 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-06-01 03:12:48,868 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10255) 
2020-06-01 03:12:48,868 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=30000-32767) 
2020-06-01 03:12:48,868 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6783) 
2020-06-01 03:12:48,870 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=80) 
2020-06-01 03:12:48,871 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=8080) 
2020-06-01 03:12:49,414 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=10250)
2020-06-01 03:12:49,424 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=10250)
2020-06-01 03:12:50,049 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=10255)
2020-06-01 03:12:50,547 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=30000-32767)
2020-06-01 03:12:50,713 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=10255)
2020-06-01 03:12:51,085 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=6783)
2020-06-01 03:12:51,224 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=30000-32767)
2020-06-01 03:12:51,611 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=80)
2020-06-01 03:12:51,741 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=6783)
2020-06-01 03:12:52,124 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=8080)
2020-06-01 03:12:52,260 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=80)
2020-06-01 03:12:52,748 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=8080)
2020-06-01 03:12:52,763 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ****************************************************************************
2020-06-01 03:12:53,100 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:53,113 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:53,130 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:53,143 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *******************************************************************
2020-06-01 03:12:53,567 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:53,579 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:53,625 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:53,638 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ***********************************************************
2020-06-01 03:12:54,266 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:12:54,276 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:12:54,284 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-06-01 03:12:54,574 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:12:54,611 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:12:54,622 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-06-01 03:12:54,635 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] *************************************************************
2020-06-01 03:12:54,979 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:54,989 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:55,003 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:55,016 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ************************************************************
2020-06-01 03:12:55,656 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:12:55,671 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:12:55,681 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:12:55,694 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] *********************************************************
2020-06-01 03:17:53,938 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:18:00,267 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:18:02,868 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:18:02,880 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *****************************************************************
2020-06-01 03:18:05,610 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=docker)
2020-06-01 03:18:05,707 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=docker)
2020-06-01 03:18:05,756 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=docker)
2020-06-01 03:18:06,316 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=kubelet)
2020-06-01 03:18:06,447 p=4996 u=root n=ansible | changed: [node12.lab.example.com] => (item=kubelet)
2020-06-01 03:18:06,486 p=4996 u=root n=ansible | changed: [node11.lab.example.com] => (item=kubelet)
2020-06-01 03:18:06,502 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] ***************************************************
2020-06-01 03:18:06,870 p=4996 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:18:06,903 p=4996 u=root n=ansible | ok: [node11.lab.example.com]
2020-06-01 03:18:06,919 p=4996 u=root n=ansible | ok: [node12.lab.example.com]
2020-06-01 03:18:06,933 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] **********************************
2020-06-01 03:18:07,008 p=4996 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:18:07,018 p=4996 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:18:07,034 p=4996 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-master-setup.yml for nodea.lab.example.com
2020-06-01 03:18:07,057 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] ***************************************************************
2020-06-01 03:22:09,800 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:22:09,812 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] **************************************************************
2020-06-01 03:22:10,131 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=mkdir -p ~/.kube)
2020-06-01 03:22:10,416 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config)
2020-06-01 03:22:10,685 p=4996 u=root n=ansible | changed: [nodea.lab.example.com] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config)
2020-06-01 03:22:10,687 p=4996 u=root n=ansible | [WARNING]: Consider using the file module with state=directory rather than running 'mkdir'.  If you need to use command because
file is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of
this message.

2020-06-01 03:22:10,687 p=4996 u=root n=ansible | [WARNING]: Consider using 'become', 'become_method', and 'become_user' rather than running sudo

2020-06-01 03:22:10,700 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *****************************************************************************
2020-06-01 03:22:11,015 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:22:11,028 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] ***************************************************************
2020-06-01 03:22:11,072 p=4996 u=root n=ansible | ok: [nodea.lab.example.com]
2020-06-01 03:22:11,086 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] **********************************
2020-06-01 03:22:11,146 p=4996 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-06-01 03:22:11,199 p=4996 u=root n=ansible | included: /tmp/ansible/kubernetes/deploy_kubernetes/tasks/k8-worker-setup.yml for node11.lab.example.com, node12.lab.example.com
2020-06-01 03:22:11,224 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] ***********************************************************
2020-06-01 03:22:21,381 p=4996 u=root n=ansible | changed: [node11.lab.example.com]
2020-06-01 03:22:21,387 p=4996 u=root n=ansible | changed: [node12.lab.example.com]
2020-06-01 03:22:21,400 p=4996 u=root n=ansible | TASK [deploy_kubernetes : 15. Ending with role deployment] *************************************************************************
2020-06-01 03:22:21,424 p=4996 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-06-01 03:22:21,443 p=4996 u=root n=ansible | ok: [node11.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-06-01 03:22:21,453 p=4996 u=root n=ansible | ok: [node12.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-06-01 03:22:21,468 p=4996 u=root n=ansible | TASK [Post-Requisite Configuring | weave | network] ********************************************************************************
2020-06-01 03:22:21,546 p=4996 u=root n=ansible | skipping: [node11.lab.example.com]
2020-06-01 03:22:21,553 p=4996 u=root n=ansible | skipping: [node12.lab.example.com]
2020-06-01 03:22:24,100 p=4996 u=root n=ansible | changed: [nodea.lab.example.com]
2020-06-01 03:22:24,103 p=4996 u=root n=ansible | PLAY RECAP *************************************************************************************************************************
2020-06-01 03:22:24,103 p=4996 u=root n=ansible | node11.lab.example.com     : ok=19   changed=14   unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2020-06-01 03:22:24,103 p=4996 u=root n=ansible | node12.lab.example.com     : ok=19   changed=14   unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2020-06-01 03:22:24,104 p=4996 u=root n=ansible | nodea.lab.example.com      : ok=23   changed=17   unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2020-07-12 12:30:51,528 p=1572 u=root n=ansible | [DEPRECATION WARNING]: The TRANSFORM_INVALID_GROUP_CHARS settings is set to allow bad characters in group names by default, this will
 change, but still be user configurable on deprecation. This feature will be removed in version 2.10. Deprecation warnings can be 
disabled by setting deprecation_warnings=False in ansible.cfg.
2020-07-12 12:30:51,528 p=1572 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:31:00,400 p=1572 u=root n=ansible | nodeb.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:00,472 p=1572 u=root n=ansible | nodec.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:00,510 p=1572 u=root n=ansible | noded.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:00,556 p=1572 u=root n=ansible | nodea.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:04,642 p=1572 u=root n=ansible | master.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:28,101 p=1674 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:31:30,113 p=1674 u=root n=ansible | nodeb.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:30,118 p=1674 u=root n=ansible | nodea.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:30,198 p=1674 u=root n=ansible | nodec.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:30,199 p=1674 u=root n=ansible | noded.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:31:30,417 p=1674 u=root n=ansible | master.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:32:14,292 p=1753 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:32:14,932 p=1753 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ************************************
2020-07-12 12:32:14,967 p=1753 u=root n=ansible | TASK [Gathering Facts] ***************************************************************************************************************
2020-07-12 12:32:20,263 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:32:20,470 p=1753 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:32:20,807 p=1753 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:32:20,982 p=1753 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:32:28,617 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:32:28,672 p=1753 u=root n=ansible | TASK [Verifying if enough resources Present] *****************************************************************************************
2020-07-12 12:32:28,959 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:32:28,962 p=1753 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:32:28,965 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:32:28,965 p=1753 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:32:28,970 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:32:28,996 p=1753 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-07-12 12:32:29,206 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:32:29,207 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:32:29,208 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:32:29,229 p=1753 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:32:29,280 p=1753 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:32:29,305 p=1753 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-07-12 12:32:30,812 p=1753 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:32:30,936 p=1753 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:32:30,940 p=1753 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:32:30,995 p=1753 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:32:31,212 p=1753 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:32:31,236 p=1753 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-07-12 12:32:31,310 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:32:31,384 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:32:31,385 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:32:31,396 p=1753 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:32:31,415 p=1753 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:32:31,447 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] **************************************************************************
2020-07-12 12:32:31,483 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:32:31,514 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:32:31,545 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:32:31,574 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:32:31,587 p=1753 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:32:31,614 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-07-12 12:32:33,631 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:32:33,643 p=1753 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:32:33,679 p=1753 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:32:33,685 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:32:33,687 p=1753 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:32:33,711 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-07-12 12:32:34,817 p=1753 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:32:34,821 p=1753 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:32:34,826 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:32:34,841 p=1753 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:32:34,923 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:32:34,947 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-07-12 12:32:35,085 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6443) 
2020-07-12 12:32:35,086 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=2379-2380) 
2020-07-12 12:32:35,087 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=6443) 
2020-07-12 12:32:35,087 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=2379-2380) 
2020-07-12 12:32:35,088 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10250) 
2020-07-12 12:32:35,089 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10251) 
2020-07-12 12:32:35,089 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10252) 
2020-07-12 12:32:35,089 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=80) 
2020-07-12 12:32:35,090 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=8080) 
2020-07-12 12:32:35,144 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-07-12 12:32:35,145 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10251) 
2020-07-12 12:32:35,146 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10252) 
2020-07-12 12:32:35,146 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=80) 
2020-07-12 12:32:35,147 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=8080) 
2020-07-12 12:32:35,159 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=6443) 
2020-07-12 12:32:35,160 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=2379-2380) 
2020-07-12 12:32:35,160 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10250) 
2020-07-12 12:32:35,160 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10251) 
2020-07-12 12:32:35,161 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10252) 
2020-07-12 12:32:35,161 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=80) 
2020-07-12 12:32:35,162 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=8080) 
2020-07-12 12:32:35,177 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=6443) 
2020-07-12 12:32:35,178 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=2379-2380) 
2020-07-12 12:32:35,179 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10250) 
2020-07-12 12:32:35,180 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10251) 
2020-07-12 12:32:35,181 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10252) 
2020-07-12 12:32:35,182 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=80) 
2020-07-12 12:32:35,182 p=1753 u=root n=ansible | skipping: [noded.lab.example.com] => (item=8080) 
2020-07-12 12:32:36,020 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=6443)
2020-07-12 12:32:36,587 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=2379-2380)
2020-07-12 12:32:37,132 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=10250)
2020-07-12 12:32:37,684 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=10251)
2020-07-12 12:32:38,227 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=10252)
2020-07-12 12:32:38,800 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=80)
2020-07-12 12:32:39,365 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=8080)
2020-07-12 12:32:39,390 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-07-12 12:32:39,679 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=10250) 
2020-07-12 12:32:39,680 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=10255) 
2020-07-12 12:32:39,703 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=30000-32767) 
2020-07-12 12:32:39,712 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=6783) 
2020-07-12 12:32:39,713 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=80) 
2020-07-12 12:32:39,713 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=8080) 
2020-07-12 12:32:40,530 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-07-12 12:32:40,538 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=10250)
2020-07-12 12:32:40,771 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=10250)
2020-07-12 12:32:40,901 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=10250)
2020-07-12 12:32:41,786 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=10255)
2020-07-12 12:32:41,932 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10255)
2020-07-12 12:32:42,103 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=10255)
2020-07-12 12:32:42,164 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=10255)
2020-07-12 12:32:43,060 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=30000-32767)
2020-07-12 12:32:43,347 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=30000-32767)
2020-07-12 12:32:43,463 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=30000-32767)
2020-07-12 12:32:43,490 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=30000-32767)
2020-07-12 12:32:44,468 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=6783)
2020-07-12 12:32:44,604 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6783)
2020-07-12 12:32:44,624 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=6783)
2020-07-12 12:32:44,790 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=6783)
2020-07-12 12:32:45,902 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=80)
2020-07-12 12:32:45,973 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=80)
2020-07-12 12:32:46,100 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=80)
2020-07-12 12:32:46,121 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=80)
2020-07-12 12:32:47,352 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=8080)
2020-07-12 12:32:47,388 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=8080)
2020-07-12 12:32:47,456 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=8080)
2020-07-12 12:32:47,588 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=8080)
2020-07-12 12:32:47,618 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-07-12 12:32:48,638 p=1753 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:32:48,725 p=1753 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:32:48,751 p=1753 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:32:48,766 p=1753 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:32:48,791 p=1753 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:32:48,817 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-07-12 12:32:48,889 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:32:48,963 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:32:48,976 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:32:48,984 p=1753 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:32:48,996 p=1753 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:32:49,020 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] *************************************************************
2020-07-12 12:32:50,231 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:32:50,241 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:32:50,257 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:32:50,272 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:32:50,282 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:32:51,245 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:32:51,269 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:32:51,283 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:32:51,298 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:32:51,345 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:32:51,370 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-07-12 12:32:52,218 p=1753 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:32:52,258 p=1753 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:32:52,357 p=1753 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:32:52,418 p=1753 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:32:52,466 p=1753 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:32:52,489 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-07-12 12:32:54,153 p=1753 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:32:54,166 p=1753 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:32:54,208 p=1753 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:32:54,283 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:32:54,338 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:32:54,375 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ***********************************************************
2020-07-12 12:33:06,178 p=1753 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:33:06,727 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:33:06,860 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:33:06,876 p=1753 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:33:07,454 p=1753 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:33:07,502 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *******************************************************************
2020-07-12 12:33:09,055 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=docker)
2020-07-12 12:33:09,079 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=docker)
2020-07-12 12:33:09,336 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=docker)
2020-07-12 12:33:09,355 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=docker)
2020-07-12 12:33:09,405 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=docker)
2020-07-12 12:33:10,189 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=kubelet)
2020-07-12 12:33:10,208 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=kubelet)
2020-07-12 12:33:10,299 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=kubelet)
2020-07-12 12:33:10,517 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=kubelet)
2020-07-12 12:33:10,528 p=1753 u=root n=ansible | ok: [master.lab.example.com] => (item=kubelet)
2020-07-12 12:33:10,558 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] *****************************************************
2020-07-12 12:33:11,618 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:33:11,619 p=1753 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:33:11,745 p=1753 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:33:11,781 p=1753 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:33:11,844 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:33:11,870 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] ************************************
2020-07-12 12:33:11,948 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:33:12,046 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:33:12,048 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:33:12,066 p=1753 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:33:12,144 p=1753 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-master-setup.yml for master.lab.example.com
2020-07-12 12:33:12,182 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] *****************************************************************
2020-07-12 12:33:12,227 p=1753 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:33:12,252 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ****************************************************************
2020-07-12 12:33:12,299 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=mkdir -p ~/.kube) 
2020-07-12 12:33:12,305 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config) 
2020-07-12 12:33:12,312 p=1753 u=root n=ansible | skipping: [master.lab.example.com] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config) 
2020-07-12 12:33:12,337 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *******************************************************************************
2020-07-12 12:33:13,268 p=1753 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:33:13,300 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] *****************************************************************
2020-07-12 12:33:13,347 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:33:13,374 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] ************************************
2020-07-12 12:33:13,558 p=1753 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:33:13,667 p=1753 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-worker-setup.yml for nodea.lab.example.com, nodeb.lab.example.com, nodec.lab.example.com, noded.lab.example.com
2020-07-12 12:33:13,712 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] *************************************************************
2020-07-12 12:33:14,511 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:33:14,598 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:33:14,602 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:33:14,677 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:33:14,701 p=1753 u=root n=ansible | TASK [deploy_kubernetes : 15. Ending with role deployment] ***************************************************************************
2020-07-12 12:33:14,736 p=1753 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:33:14,766 p=1753 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:33:14,798 p=1753 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:33:14,838 p=1753 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:33:14,848 p=1753 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:33:14,880 p=1753 u=root n=ansible | TASK [Post-Requisite Configuring | weave | network] **********************************************************************************
2020-07-12 12:33:15,044 p=1753 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:33:15,045 p=1753 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:33:15,046 p=1753 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:33:15,047 p=1753 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:33:15,418 p=1753 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:33:15,421 p=1753 u=root n=ansible | PLAY RECAP ***************************************************************************************************************************
2020-07-12 12:33:15,421 p=1753 u=root n=ansible | master.lab.example.com     : ok=18   changed=4    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
2020-07-12 12:33:15,421 p=1753 u=root n=ansible | nodea.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:33:15,421 p=1753 u=root n=ansible | nodeb.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:33:15,421 p=1753 u=root n=ansible | nodec.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:33:15,421 p=1753 u=root n=ansible | noded.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:33:52,657 p=2763 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:33:52,960 p=2763 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ************************************
2020-07-12 12:33:52,976 p=2763 u=root n=ansible | TASK [Gathering Facts] ***************************************************************************************************************
2020-07-12 12:33:56,047 p=2763 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:33:56,151 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:33:56,243 p=2763 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:33:56,266 p=2763 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:33:57,080 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:33:57,104 p=2763 u=root n=ansible | TASK [Verifying if enough resources Present] *****************************************************************************************
2020-07-12 12:33:57,164 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:33:57,250 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:33:57,251 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:33:57,254 p=2763 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:33:57,278 p=2763 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:33:57,303 p=2763 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-07-12 12:33:57,369 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:33:57,435 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:33:57,436 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:33:57,455 p=2763 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:33:57,476 p=2763 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:33:57,501 p=2763 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-07-12 12:33:58,876 p=2763 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:33:58,890 p=2763 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:33:58,895 p=2763 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:33:58,975 p=2763 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:33:59,267 p=2763 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:33:59,292 p=2763 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-07-12 12:33:59,395 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:33:59,433 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:33:59,439 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:33:59,475 p=2763 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:33:59,488 p=2763 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:33:59,516 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] **************************************************************************
2020-07-12 12:33:59,552 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:33:59,587 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:33:59,633 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:33:59,681 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:33:59,690 p=2763 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:33:59,717 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-07-12 12:34:01,932 p=2763 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:34:01,959 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:34:01,964 p=2763 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:34:02,034 p=2763 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:34:02,654 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:02,694 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-07-12 12:34:04,399 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:34:04,410 p=2763 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:34:04,411 p=2763 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:34:04,415 p=2763 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:34:04,763 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:04,786 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-07-12 12:34:04,957 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6443) 
2020-07-12 12:34:04,957 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=2379-2380) 
2020-07-12 12:34:04,958 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-07-12 12:34:04,958 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10251) 
2020-07-12 12:34:04,959 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10252) 
2020-07-12 12:34:04,960 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=80) 
2020-07-12 12:34:04,961 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=8080) 
2020-07-12 12:34:04,962 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=6443) 
2020-07-12 12:34:04,962 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=2379-2380) 
2020-07-12 12:34:04,963 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10250) 
2020-07-12 12:34:04,963 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10251) 
2020-07-12 12:34:04,963 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10252) 
2020-07-12 12:34:04,964 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=80) 
2020-07-12 12:34:04,964 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=8080) 
2020-07-12 12:34:04,983 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=6443) 
2020-07-12 12:34:04,984 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=2379-2380) 
2020-07-12 12:34:04,984 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10250) 
2020-07-12 12:34:05,002 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10251) 
2020-07-12 12:34:05,003 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10252) 
2020-07-12 12:34:05,003 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=80) 
2020-07-12 12:34:05,004 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=8080) 
2020-07-12 12:34:05,032 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=6443) 
2020-07-12 12:34:05,032 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=2379-2380) 
2020-07-12 12:34:05,034 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10250) 
2020-07-12 12:34:05,038 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10251) 
2020-07-12 12:34:05,038 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10252) 
2020-07-12 12:34:05,038 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=80) 
2020-07-12 12:34:05,039 p=2763 u=root n=ansible | skipping: [noded.lab.example.com] => (item=8080) 
2020-07-12 12:34:05,889 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=6443)
2020-07-12 12:34:06,673 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=2379-2380)
2020-07-12 12:34:08,894 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=10250)
2020-07-12 12:34:11,989 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=10251)
2020-07-12 12:34:14,789 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=10252)
2020-07-12 12:34:16,553 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=80)
2020-07-12 12:34:19,067 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=8080)
2020-07-12 12:34:19,099 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-07-12 12:34:19,460 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=10250) 
2020-07-12 12:34:19,461 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=10255) 
2020-07-12 12:34:19,462 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=30000-32767) 
2020-07-12 12:34:19,462 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=6783) 
2020-07-12 12:34:19,463 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=80) 
2020-07-12 12:34:19,482 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=8080) 
2020-07-12 12:34:20,710 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=10250)
2020-07-12 12:34:20,874 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=10250)
2020-07-12 12:34:20,986 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-07-12 12:34:21,000 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=10250)
2020-07-12 12:34:22,057 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=10255)
2020-07-12 12:34:22,253 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=10255)
2020-07-12 12:34:22,406 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10255)
2020-07-12 12:34:22,468 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=10255)
2020-07-12 12:34:23,321 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=30000-32767)
2020-07-12 12:34:24,085 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=30000-32767)
2020-07-12 12:34:24,112 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=30000-32767)
2020-07-12 12:34:24,139 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=30000-32767)
2020-07-12 12:34:24,895 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=6783)
2020-07-12 12:34:25,660 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=6783)
2020-07-12 12:34:25,685 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6783)
2020-07-12 12:34:25,731 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=6783)
2020-07-12 12:34:26,371 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=80)
2020-07-12 12:34:27,232 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=80)
2020-07-12 12:34:27,326 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=80)
2020-07-12 12:34:27,378 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=80)
2020-07-12 12:34:27,856 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=8080)
2020-07-12 12:34:28,516 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=8080)
2020-07-12 12:34:28,543 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=8080)
2020-07-12 12:34:28,559 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=8080)
2020-07-12 12:34:28,594 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-07-12 12:34:29,561 p=2763 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:34:29,597 p=2763 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:34:29,623 p=2763 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:34:29,652 p=2763 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:34:31,001 p=2763 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:34:31,031 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-07-12 12:34:31,110 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:34:31,197 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:34:31,199 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:34:31,221 p=2763 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:34:31,250 p=2763 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:34:31,280 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] *************************************************************
2020-07-12 12:34:32,516 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:34:32,553 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:34:32,597 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:34:32,653 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:34:33,489 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:34:33,557 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:34:33,569 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:34:33,580 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:34:35,240 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:34:36,180 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:34:36,209 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-07-12 12:34:37,235 p=2763 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:34:37,316 p=2763 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:34:37,327 p=2763 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:34:37,372 p=2763 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:34:37,545 p=2763 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:34:37,570 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-07-12 12:34:39,150 p=2763 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:34:39,228 p=2763 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:34:39,313 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:34:39,349 p=2763 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:34:39,512 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:39,535 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ***********************************************************
2020-07-12 12:34:41,278 p=2763 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:34:41,499 p=2763 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:34:41,509 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:34:41,510 p=2763 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:34:41,871 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:41,895 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *******************************************************************
2020-07-12 12:34:43,245 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=docker)
2020-07-12 12:34:43,332 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=docker)
2020-07-12 12:34:43,411 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=docker)
2020-07-12 12:34:43,515 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=docker)
2020-07-12 12:34:43,939 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=docker)
2020-07-12 12:34:44,288 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=kubelet)
2020-07-12 12:34:44,486 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=kubelet)
2020-07-12 12:34:44,513 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=kubelet)
2020-07-12 12:34:44,661 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=kubelet)
2020-07-12 12:34:44,766 p=2763 u=root n=ansible | ok: [master.lab.example.com] => (item=kubelet)
2020-07-12 12:34:44,793 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] *****************************************************
2020-07-12 12:34:45,657 p=2763 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:34:45,712 p=2763 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:34:45,731 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:34:45,751 p=2763 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:34:45,881 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:45,906 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] ************************************
2020-07-12 12:34:45,974 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:34:46,053 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:34:46,054 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:34:46,062 p=2763 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:34:46,106 p=2763 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-master-setup.yml for master.lab.example.com
2020-07-12 12:34:46,145 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] *****************************************************************
2020-07-12 12:34:46,187 p=2763 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:34:46,211 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ****************************************************************
2020-07-12 12:34:46,262 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=mkdir -p ~/.kube) 
2020-07-12 12:34:46,265 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config) 
2020-07-12 12:34:46,271 p=2763 u=root n=ansible | skipping: [master.lab.example.com] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config) 
2020-07-12 12:34:46,293 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *******************************************************************************
2020-07-12 12:34:46,767 p=2763 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:34:46,790 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] *****************************************************************
2020-07-12 12:34:46,837 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:46,860 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] ************************************
2020-07-12 12:34:47,032 p=2763 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:34:47,118 p=2763 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-worker-setup.yml for nodea.lab.example.com, nodeb.lab.example.com, nodec.lab.example.com, noded.lab.example.com
2020-07-12 12:34:47,163 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] *************************************************************
2020-07-12 12:34:47,816 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:34:47,868 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:34:47,976 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:34:48,006 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:34:48,032 p=2763 u=root n=ansible | TASK [deploy_kubernetes : 15. Ending with role deployment] ***************************************************************************
2020-07-12 12:34:48,064 p=2763 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:34:48,090 p=2763 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:34:48,119 p=2763 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:34:48,147 p=2763 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:34:48,160 p=2763 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:34:48,185 p=2763 u=root n=ansible | TASK [Post-Requisite Configuring | weave | network] **********************************************************************************
2020-07-12 12:34:48,329 p=2763 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:34:48,330 p=2763 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:34:48,330 p=2763 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:34:48,343 p=2763 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:34:48,667 p=2763 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:34:48,669 p=2763 u=root n=ansible | PLAY RECAP ***************************************************************************************************************************
2020-07-12 12:34:48,669 p=2763 u=root n=ansible | master.lab.example.com     : ok=18   changed=4    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
2020-07-12 12:34:48,669 p=2763 u=root n=ansible | nodea.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:34:48,669 p=2763 u=root n=ansible | nodeb.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:34:48,669 p=2763 u=root n=ansible | nodec.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:34:48,670 p=2763 u=root n=ansible | noded.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 12:36:04,854 p=3774 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:36:06,706 p=3774 u=root n=ansible | nodea.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:06,721 p=3774 u=root n=ansible | master.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:06,822 p=3774 u=root n=ansible | nodec.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:06,859 p=3774 u=root n=ansible | nodeb.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:08,112 p=3774 u=root n=ansible | noded.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: ssh: connect to host noded.lab.example.com port 22: No route to host", 
    "unreachable": true
}
2020-07-12 12:36:10,575 p=3803 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:36:10,928 p=3803 u=root n=ansible | nodea.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:10,946 p=3803 u=root n=ansible | nodec.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:10,958 p=3803 u=root n=ansible | nodeb.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:10,986 p=3803 u=root n=ansible | master.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).", 
    "unreachable": true
}
2020-07-12 12:36:11,116 p=3803 u=root n=ansible | noded.lab.example.com | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: ssh: connect to host noded.lab.example.com port 22: No route to host", 
    "unreachable": true
}
2020-07-12 12:36:46,260 p=4052 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:36:48,130 p=4052 u=root n=ansible | nodeb.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:36:48,227 p=4052 u=root n=ansible | noded.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:36:48,238 p=4052 u=root n=ansible | nodec.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:36:48,248 p=4052 u=root n=ansible | nodea.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:36:48,254 p=4052 u=root n=ansible | master.lab.example.com | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
2020-07-12 12:36:52,574 p=4136 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 12:36:52,819 p=4136 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ************************************
2020-07-12 12:36:52,834 p=4136 u=root n=ansible | TASK [Gathering Facts] ***************************************************************************************************************
2020-07-12 12:36:54,732 p=4136 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:36:54,929 p=4136 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:36:54,952 p=4136 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:36:55,080 p=4136 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:36:55,194 p=4136 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:36:55,207 p=4136 u=root n=ansible | TASK [Verifying if enough resources Present] *****************************************************************************************
2020-07-12 12:36:55,279 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:36:55,297 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:36:55,337 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:36:55,345 p=4136 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:36:55,346 p=4136 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:36:55,360 p=4136 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-07-12 12:36:56,482 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:36:56,498 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:36:56,506 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:36:56,517 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:36:56,520 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:36:56,532 p=4136 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-07-12 12:36:57,306 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:36:57,467 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:36:57,483 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:36:57,489 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:36:57,503 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:36:57,516 p=4136 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-07-12 12:36:58,440 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:36:58,475 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:36:58,547 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:36:58,548 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:36:58,578 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:36:58,592 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] **************************************************************************
2020-07-12 12:36:58,613 p=4136 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:36:58,632 p=4136 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:36:58,651 p=4136 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:36:58,671 p=4136 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:36:58,680 p=4136 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 12:36:58,694 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-07-12 12:37:00,562 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:37:00,622 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:37:00,631 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:37:00,637 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:37:00,664 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:37:00,677 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-07-12 12:37:01,660 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:37:01,698 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:37:01,718 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:37:01,724 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:37:01,736 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:37:01,750 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-07-12 12:37:01,876 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6443) 
2020-07-12 12:37:01,877 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=2379-2380) 
2020-07-12 12:37:01,878 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-07-12 12:37:01,878 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10251) 
2020-07-12 12:37:01,879 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10252) 
2020-07-12 12:37:01,879 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=80) 
2020-07-12 12:37:01,894 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=8080) 
2020-07-12 12:37:01,896 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=6443) 
2020-07-12 12:37:01,896 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=2379-2380) 
2020-07-12 12:37:01,897 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10250) 
2020-07-12 12:37:01,904 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10251) 
2020-07-12 12:37:01,904 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10252) 
2020-07-12 12:37:01,905 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=80) 
2020-07-12 12:37:01,905 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=8080) 
2020-07-12 12:37:01,933 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=6443) 
2020-07-12 12:37:01,940 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=6443) 
2020-07-12 12:37:01,941 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=2379-2380) 
2020-07-12 12:37:01,941 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10250) 
2020-07-12 12:37:01,942 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10251) 
2020-07-12 12:37:01,942 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10252) 
2020-07-12 12:37:01,947 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=2379-2380) 
2020-07-12 12:37:01,948 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10250) 
2020-07-12 12:37:01,948 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10251) 
2020-07-12 12:37:01,949 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10252) 
2020-07-12 12:37:01,949 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=80) 
2020-07-12 12:37:01,949 p=4136 u=root n=ansible | skipping: [noded.lab.example.com] => (item=8080) 
2020-07-12 12:37:01,952 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=80) 
2020-07-12 12:37:01,952 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=8080) 
2020-07-12 12:37:02,647 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=6443)
2020-07-12 12:37:03,177 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=2379-2380)
2020-07-12 12:37:03,690 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=10250)
2020-07-12 12:37:04,205 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=10251)
2020-07-12 12:37:04,732 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=10252)
2020-07-12 12:37:05,247 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=80)
2020-07-12 12:37:05,769 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=8080)
2020-07-12 12:37:05,787 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-07-12 12:37:06,020 p=4136 u=root n=ansible | skipping: [master.lab.example.com] => (item=10250) 
2020-07-12 12:37:06,021 p=4136 u=root n=ansible | skipping: [master.lab.example.com] => (item=10255) 
2020-07-12 12:37:06,065 p=4136 u=root n=ansible | skipping: [master.lab.example.com] => (item=30000-32767) 
2020-07-12 12:37:06,065 p=4136 u=root n=ansible | skipping: [master.lab.example.com] => (item=6783) 
2020-07-12 12:37:06,066 p=4136 u=root n=ansible | skipping: [master.lab.example.com] => (item=80) 
2020-07-12 12:37:06,066 p=4136 u=root n=ansible | skipping: [master.lab.example.com] => (item=8080) 
2020-07-12 12:37:07,066 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10250)
2020-07-12 12:37:07,100 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=10250)
2020-07-12 12:37:07,177 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=10250)
2020-07-12 12:37:07,338 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=10250)
2020-07-12 12:37:08,024 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=10255)
2020-07-12 12:37:08,167 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=10255)
2020-07-12 12:37:08,289 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=10255)
2020-07-12 12:37:08,406 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=10255)
2020-07-12 12:37:09,181 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=30000-32767)
2020-07-12 12:37:09,273 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=30000-32767)
2020-07-12 12:37:09,380 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=30000-32767)
2020-07-12 12:37:09,523 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=30000-32767)
2020-07-12 12:37:10,174 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=6783)
2020-07-12 12:37:10,255 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=6783)
2020-07-12 12:37:10,369 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=6783)
2020-07-12 12:37:10,676 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=6783)
2020-07-12 12:37:11,343 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=80)
2020-07-12 12:37:11,400 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=80)
2020-07-12 12:37:11,549 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=80)
2020-07-12 12:37:11,922 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=80)
2020-07-12 12:37:12,420 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=8080)
2020-07-12 12:37:12,438 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=8080)
2020-07-12 12:37:12,537 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=8080)
2020-07-12 12:37:12,821 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=8080)
2020-07-12 12:37:12,835 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-07-12 12:37:13,650 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:37:13,768 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:37:13,799 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:37:13,824 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:37:13,872 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:37:13,884 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-07-12 12:37:14,807 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:37:14,855 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:37:14,877 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:37:14,906 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:37:14,955 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:37:14,967 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] *************************************************************
2020-07-12 12:37:16,063 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:37:16,102 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:37:16,128 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:37:16,138 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:37:16,341 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 12:37:16,915 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:37:16,984 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:37:16,993 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:37:17,047 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:37:17,132 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 12:37:17,145 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-07-12 12:37:17,994 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:37:17,997 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:37:18,019 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:37:18,062 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:37:18,109 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:37:18,122 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-07-12 12:37:19,601 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:37:19,739 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:37:19,767 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:37:19,794 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:37:19,795 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:37:19,808 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ***********************************************************
2020-07-12 12:45:54,236 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:46:04,683 p=4136 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 12:46:56,100 p=4136 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 12:47:12,864 p=4136 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 12:47:46,242 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 12:47:46,270 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *******************************************************************
2020-07-12 12:47:51,638 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=docker)
2020-07-12 12:47:51,999 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=docker)
2020-07-12 12:47:52,519 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=docker)
2020-07-12 12:47:52,554 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=docker)
2020-07-12 12:47:52,791 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=docker)
2020-07-12 12:47:53,245 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=kubelet)
2020-07-12 12:47:53,896 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=kubelet)
2020-07-12 12:47:54,257 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=kubelet)
2020-07-12 12:47:54,375 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=kubelet)
2020-07-12 12:47:54,442 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=kubelet)
2020-07-12 12:47:54,460 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] *****************************************************
2020-07-12 12:47:55,492 p=4136 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 12:47:55,562 p=4136 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 12:47:55,563 p=4136 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 12:47:55,581 p=4136 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:47:55,592 p=4136 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 12:47:55,606 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] ************************************
2020-07-12 12:47:55,717 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:47:55,731 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:47:55,732 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:47:55,732 p=4136 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:47:55,771 p=4136 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-master-setup.yml for master.lab.example.com
2020-07-12 12:47:55,801 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] *****************************************************************
2020-07-12 12:52:08,707 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:52:08,722 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ****************************************************************
2020-07-12 12:52:09,064 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=mkdir -p ~/.kube)
2020-07-12 12:52:09,526 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config)
2020-07-12 12:52:09,857 p=4136 u=root n=ansible | changed: [master.lab.example.com] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config)
2020-07-12 12:52:09,860 p=4136 u=root n=ansible | [WARNING]: Consider using the file module with state=directory rather than running 'mkdir'.  If you need to use command because file
is insufficient you can add 'warn: false' to this command task or set 'command_warnings=False' in ansible.cfg to get rid of this
message.

2020-07-12 12:52:09,860 p=4136 u=root n=ansible | [WARNING]: Consider using 'become', 'become_method', and 'become_user' rather than running sudo

2020-07-12 12:52:09,876 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *******************************************************************************
2020-07-12 12:52:10,287 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:52:10,301 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] *****************************************************************
2020-07-12 12:52:10,348 p=4136 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 12:52:10,362 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] ************************************
2020-07-12 12:52:10,522 p=4136 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 12:52:10,575 p=4136 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-worker-setup.yml for nodea.lab.example.com, nodeb.lab.example.com, nodec.lab.example.com, noded.lab.example.com
2020-07-12 12:52:10,607 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] *************************************************************
2020-07-12 12:52:27,606 p=4136 u=root n=ansible | changed: [nodea.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:52:27,682 p=4136 u=root n=ansible | changed: [nodec.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:52:30,380 p=4136 u=root n=ansible | changed: [noded.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:52:33,894 p=4136 u=root n=ansible | changed: [nodeb.lab.example.com] => (item=master.lab.example.com)
2020-07-12 12:52:33,908 p=4136 u=root n=ansible | TASK [deploy_kubernetes : 15. Ending with role deployment] ***************************************************************************
2020-07-12 12:52:33,930 p=4136 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:52:33,955 p=4136 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:52:33,978 p=4136 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:52:34,001 p=4136 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:52:34,012 p=4136 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 12:52:34,027 p=4136 u=root n=ansible | TASK [Post-Requisite Configuring | weave | network] **********************************************************************************
2020-07-12 12:52:34,112 p=4136 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 12:52:34,144 p=4136 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 12:52:34,167 p=4136 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 12:52:34,168 p=4136 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 12:52:45,469 p=4136 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 12:52:45,472 p=4136 u=root n=ansible | PLAY RECAP ***************************************************************************************************************************
2020-07-12 12:52:45,472 p=4136 u=root n=ansible | master.lab.example.com     : ok=23   changed=17   unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2020-07-12 12:52:45,472 p=4136 u=root n=ansible | nodea.lab.example.com      : ok=19   changed=14   unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2020-07-12 12:52:45,473 p=4136 u=root n=ansible | nodeb.lab.example.com      : ok=19   changed=14   unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2020-07-12 12:52:45,473 p=4136 u=root n=ansible | nodec.lab.example.com      : ok=19   changed=14   unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2020-07-12 12:52:45,473 p=4136 u=root n=ansible | noded.lab.example.com      : ok=19   changed=14   unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2020-07-12 13:29:05,883 p=5418 u=root n=ansible | [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2020-07-12 13:29:06,256 p=5418 u=root n=ansible | PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ************************************
2020-07-12 13:29:06,278 p=5418 u=root n=ansible | TASK [Gathering Facts] ***************************************************************************************************************
2020-07-12 13:29:10,131 p=5418 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 13:29:10,143 p=5418 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 13:29:10,202 p=5418 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 13:29:10,258 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 13:29:18,048 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:29:18,086 p=5418 u=root n=ansible | TASK [Verifying if enough resources Present] *****************************************************************************************
2020-07-12 13:29:18,273 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 13:29:18,274 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 13:29:18,275 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 13:29:18,283 p=5418 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 13:29:18,357 p=5418 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 13:29:18,385 p=5418 u=root n=ansible | TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-07-12 13:29:18,555 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 13:29:18,556 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 13:29:18,557 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 13:29:18,564 p=5418 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 13:29:18,603 p=5418 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 13:29:18,632 p=5418 u=root n=ansible | TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-07-12 13:29:20,002 p=5418 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 13:29:20,071 p=5418 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 13:29:20,075 p=5418 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 13:29:20,118 p=5418 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 13:29:21,897 p=5418 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 13:29:21,922 p=5418 u=root n=ansible | TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-07-12 13:29:22,100 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 13:29:22,101 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 13:29:22,102 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 13:29:22,120 p=5418 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 13:29:22,150 p=5418 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 13:29:22,181 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 0. Starting with role deployment] **************************************************************************
2020-07-12 13:29:22,240 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 13:29:22,279 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 13:29:22,317 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 13:29:22,350 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 13:29:22,365 p=5418 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-07-12 13:29:22,396 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-07-12 13:29:24,519 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 13:29:24,520 p=5418 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 13:29:24,534 p=5418 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 13:29:24,553 p=5418 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 13:29:25,996 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:29:26,023 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-07-12 13:29:27,317 p=5418 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 13:29:27,319 p=5418 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 13:29:27,353 p=5418 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 13:29:27,353 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 13:29:28,179 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:29:28,204 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-07-12 13:29:28,356 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=6443) 
2020-07-12 13:29:28,358 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=2379-2380) 
2020-07-12 13:29:28,359 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10250) 
2020-07-12 13:29:28,360 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10251) 
2020-07-12 13:29:28,361 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=10252) 
2020-07-12 13:29:28,362 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=80) 
2020-07-12 13:29:28,362 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com] => (item=8080) 
2020-07-12 13:29:28,445 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=6443) 
2020-07-12 13:29:28,446 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=2379-2380) 
2020-07-12 13:29:28,450 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10250) 
2020-07-12 13:29:28,451 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10251) 
2020-07-12 13:29:28,451 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=10252) 
2020-07-12 13:29:28,452 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=80) 
2020-07-12 13:29:28,453 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com] => (item=8080) 
2020-07-12 13:29:28,454 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=6443) 
2020-07-12 13:29:28,455 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=2379-2380) 
2020-07-12 13:29:28,456 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10250) 
2020-07-12 13:29:28,456 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10251) 
2020-07-12 13:29:28,456 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=10252) 
2020-07-12 13:29:28,457 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=80) 
2020-07-12 13:29:28,457 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com] => (item=8080) 
2020-07-12 13:29:28,472 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=6443) 
2020-07-12 13:29:28,473 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=2379-2380) 
2020-07-12 13:29:28,497 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10250) 
2020-07-12 13:29:28,499 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10251) 
2020-07-12 13:29:28,500 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=10252) 
2020-07-12 13:29:28,501 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=80) 
2020-07-12 13:29:28,501 p=5418 u=root n=ansible | skipping: [noded.lab.example.com] => (item=8080) 
2020-07-12 13:29:31,477 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=6443)
2020-07-12 13:29:32,691 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=2379-2380)
2020-07-12 13:29:33,298 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=10250)
2020-07-12 13:29:33,837 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=10251)
2020-07-12 13:29:34,734 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=10252)
2020-07-12 13:29:35,755 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=80)
2020-07-12 13:29:36,319 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=8080)
2020-07-12 13:29:36,343 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-07-12 13:29:36,655 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=10250) 
2020-07-12 13:29:36,656 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=10255) 
2020-07-12 13:29:36,697 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=30000-32767) 
2020-07-12 13:29:36,700 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=6783) 
2020-07-12 13:29:36,708 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=80) 
2020-07-12 13:29:36,708 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=8080) 
2020-07-12 13:29:37,659 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=10250)
2020-07-12 13:29:37,739 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=10250)
2020-07-12 13:29:37,852 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10250)
2020-07-12 13:29:38,018 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=10250)
2020-07-12 13:29:38,931 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=10255)
2020-07-12 13:29:38,936 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=10255)
2020-07-12 13:29:39,007 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=10255)
2020-07-12 13:29:39,392 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=10255)
2020-07-12 13:29:40,028 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=30000-32767)
2020-07-12 13:29:40,094 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=30000-32767)
2020-07-12 13:29:40,234 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=30000-32767)
2020-07-12 13:29:40,831 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=30000-32767)
2020-07-12 13:29:41,371 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=6783)
2020-07-12 13:29:41,412 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=6783)
2020-07-12 13:29:41,729 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=6783)
2020-07-12 13:29:42,160 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=6783)
2020-07-12 13:29:42,452 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=80)
2020-07-12 13:29:42,845 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=80)
2020-07-12 13:29:42,930 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=80)
2020-07-12 13:29:43,509 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=80)
2020-07-12 13:29:43,709 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=8080)
2020-07-12 13:29:43,890 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=8080)
2020-07-12 13:29:43,926 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=8080)
2020-07-12 13:29:44,248 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=8080)
2020-07-12 13:29:44,273 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-07-12 13:29:45,021 p=5418 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 13:29:45,089 p=5418 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 13:29:45,228 p=5418 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 13:29:45,248 p=5418 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 13:29:45,742 p=5418 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 13:29:45,763 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-07-12 13:29:45,833 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 13:29:45,917 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 13:29:45,918 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 13:29:45,935 p=5418 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 13:29:45,944 p=5418 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 13:29:45,967 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] *************************************************************
2020-07-12 13:29:47,254 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 13:29:47,381 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 13:29:47,407 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 13:29:47,407 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 13:29:48,187 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 13:29:48,382 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 13:29:48,412 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 13:29:48,424 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 13:29:49,357 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-07-12 13:29:50,041 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=net.bridge.bridge-nf-call-iptables)
2020-07-12 13:29:50,066 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-07-12 13:29:51,116 p=5418 u=root n=ansible | changed: [nodea.lab.example.com]
2020-07-12 13:29:51,143 p=5418 u=root n=ansible | changed: [nodec.lab.example.com]
2020-07-12 13:29:51,221 p=5418 u=root n=ansible | changed: [nodeb.lab.example.com]
2020-07-12 13:29:51,225 p=5418 u=root n=ansible | changed: [noded.lab.example.com]
2020-07-12 13:29:52,711 p=5418 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 13:29:52,737 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-07-12 13:29:54,498 p=5418 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 13:29:54,505 p=5418 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 13:29:54,550 p=5418 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 13:29:54,577 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 13:29:57,406 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:29:57,440 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ***********************************************************
2020-07-12 13:29:59,517 p=5418 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 13:29:59,572 p=5418 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 13:29:59,600 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 13:29:59,629 p=5418 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 13:30:03,749 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:30:03,776 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] *******************************************************************
2020-07-12 13:30:05,967 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=docker)
2020-07-12 13:30:06,013 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=docker)
2020-07-12 13:30:06,033 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=docker)
2020-07-12 13:30:06,155 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=docker)
2020-07-12 13:30:07,073 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=kubelet)
2020-07-12 13:30:07,111 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=kubelet)
2020-07-12 13:30:07,170 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=kubelet)
2020-07-12 13:30:07,206 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=kubelet)
2020-07-12 13:30:09,278 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=docker)
2020-07-12 13:30:10,031 p=5418 u=root n=ansible | ok: [master.lab.example.com] => (item=kubelet)
2020-07-12 13:30:10,057 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] *****************************************************
2020-07-12 13:30:10,955 p=5418 u=root n=ansible | ok: [nodea.lab.example.com]
2020-07-12 13:30:10,980 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com]
2020-07-12 13:30:11,041 p=5418 u=root n=ansible | ok: [noded.lab.example.com]
2020-07-12 13:30:11,083 p=5418 u=root n=ansible | ok: [nodec.lab.example.com]
2020-07-12 13:30:11,484 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:30:11,507 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] ************************************
2020-07-12 13:30:11,644 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 13:30:11,645 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 13:30:11,661 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 13:30:11,665 p=5418 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 13:30:11,710 p=5418 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-master-setup.yml for master.lab.example.com
2020-07-12 13:30:11,748 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] *****************************************************************
2020-07-12 13:30:11,812 p=5418 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 13:30:11,834 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ****************************************************************
2020-07-12 13:30:11,888 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=mkdir -p ~/.kube) 
2020-07-12 13:30:11,893 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config) 
2020-07-12 13:30:11,897 p=5418 u=root n=ansible | skipping: [master.lab.example.com] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config) 
2020-07-12 13:30:11,921 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 13.3. Generate join command] *******************************************************************************
2020-07-12 13:30:12,539 p=5418 u=root n=ansible | changed: [master.lab.example.com]
2020-07-12 13:30:12,561 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 13.4. Setting up the command use globally] *****************************************************************
2020-07-12 13:30:12,607 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:30:12,631 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] ************************************
2020-07-12 13:30:12,827 p=5418 u=root n=ansible | skipping: [master.lab.example.com]
2020-07-12 13:30:12,918 p=5418 u=root n=ansible | included: /tmp/kubernetesCluster/deploy_kubernetes/tasks/k8-worker-setup.yml for nodea.lab.example.com, nodeb.lab.example.com, nodec.lab.example.com, noded.lab.example.com
2020-07-12 13:30:12,961 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] *************************************************************
2020-07-12 13:30:13,876 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => (item=master.lab.example.com)
2020-07-12 13:30:13,950 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => (item=master.lab.example.com)
2020-07-12 13:30:13,965 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => (item=master.lab.example.com)
2020-07-12 13:30:13,976 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => (item=master.lab.example.com)
2020-07-12 13:30:14,006 p=5418 u=root n=ansible | TASK [deploy_kubernetes : 15. Ending with role deployment] ***************************************************************************
2020-07-12 13:30:14,051 p=5418 u=root n=ansible | ok: [nodea.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 13:30:14,097 p=5418 u=root n=ansible | ok: [nodeb.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 13:30:14,131 p=5418 u=root n=ansible | ok: [nodec.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 13:30:14,163 p=5418 u=root n=ansible | ok: [noded.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 13:30:14,174 p=5418 u=root n=ansible | ok: [master.lab.example.com] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-07-12 13:30:14,198 p=5418 u=root n=ansible | TASK [Post-Requisite Configuring | weave | network] **********************************************************************************
2020-07-12 13:30:14,303 p=5418 u=root n=ansible | skipping: [nodea.lab.example.com]
2020-07-12 13:30:14,332 p=5418 u=root n=ansible | skipping: [nodeb.lab.example.com]
2020-07-12 13:30:14,335 p=5418 u=root n=ansible | skipping: [nodec.lab.example.com]
2020-07-12 13:30:14,354 p=5418 u=root n=ansible | skipping: [noded.lab.example.com]
2020-07-12 13:30:14,736 p=5418 u=root n=ansible | ok: [master.lab.example.com]
2020-07-12 13:30:14,740 p=5418 u=root n=ansible | PLAY RECAP ***************************************************************************************************************************
2020-07-12 13:30:14,740 p=5418 u=root n=ansible | master.lab.example.com     : ok=18   changed=4    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
2020-07-12 13:30:14,740 p=5418 u=root n=ansible | nodea.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 13:30:14,740 p=5418 u=root n=ansible | nodeb.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 13:30:14,740 p=5418 u=root n=ansible | nodec.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-07-12 13:30:14,740 p=5418 u=root n=ansible | noded.lab.example.com      : ok=16   changed=3    unreachable=0    failed=0    skipped=7    rescued=0    ignored=0   
2020-08-04 10:19:50,970 p=2430 u=root |  k8-master | SUCCESS => {
    "changed": false, 
    "failed": false, 
    "ping": "pong"
}
2020-08-04 10:19:51,041 p=2430 u=root |  k8-node | SUCCESS => {
    "changed": false, 
    "failed": false, 
    "ping": "pong"
}
2020-08-04 10:20:23,458 p=2473 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ************************************
2020-08-04 10:20:23,466 p=2473 u=root |  TASK [Gathering Facts] ***************************************************************************************************************
2020-08-04 10:20:25,528 p=2473 u=root |  ok: [k8-master]
2020-08-04 10:20:27,603 p=2473 u=root |  ok: [k8-node]
2020-08-04 10:20:27,773 p=2473 u=root |  TASK [Verifying if enough resources Present] *****************************************************************************************
2020-08-04 10:20:27,827 p=2473 u=root |  skipping: [k8-master]
2020-08-04 10:20:27,842 p=2473 u=root |  skipping: [k8-node]
2020-08-04 10:20:27,850 p=2473 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-08-04 10:20:28,652 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:28,772 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:28,778 p=2473 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-08-04 10:20:29,154 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:29,393 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:29,400 p=2473 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-08-04 10:20:29,789 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:29,795 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:29,814 p=2473 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] **************************************************************************
2020-08-04 10:20:29,867 p=2473 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-04 10:20:29,879 p=2473 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-04 10:20:29,885 p=2473 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-08-04 10:20:30,896 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:30,898 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:30,903 p=2473 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-08-04 10:20:31,494 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:31,536 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:31,541 p=2473 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-08-04 10:20:31,668 p=2473 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-04 10:20:31,668 p=2473 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-04 10:20:31,669 p=2473 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-04 10:20:31,681 p=2473 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-04 10:20:31,682 p=2473 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-04 10:20:31,682 p=2473 u=root |  skipping: [k8-node] => (item=80) 
2020-08-04 10:20:31,682 p=2473 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-04 10:20:32,559 p=2473 u=root |  changed: [k8-master] => (item=6443)
2020-08-04 10:20:33,229 p=2473 u=root |  changed: [k8-master] => (item=2379-2380)
2020-08-04 10:20:33,866 p=2473 u=root |  changed: [k8-master] => (item=10250)
2020-08-04 10:20:34,458 p=2473 u=root |  changed: [k8-master] => (item=10251)
2020-08-04 10:20:35,209 p=2473 u=root |  changed: [k8-master] => (item=10252)
2020-08-04 10:20:35,976 p=2473 u=root |  changed: [k8-master] => (item=80)
2020-08-04 10:20:36,856 p=2473 u=root |  changed: [k8-master] => (item=8080)
2020-08-04 10:20:36,861 p=2473 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-08-04 10:20:36,893 p=2473 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-04 10:20:36,893 p=2473 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-04 10:20:36,894 p=2473 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-04 10:20:36,896 p=2473 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-04 10:20:36,897 p=2473 u=root |  skipping: [k8-master] => (item=80) 
2020-08-04 10:20:36,897 p=2473 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-04 10:20:37,678 p=2473 u=root |  changed: [k8-node] => (item=10250)
2020-08-04 10:20:38,297 p=2473 u=root |  changed: [k8-node] => (item=10255)
2020-08-04 10:20:38,918 p=2473 u=root |  changed: [k8-node] => (item=30000-32767)
2020-08-04 10:20:39,486 p=2473 u=root |  changed: [k8-node] => (item=6783)
2020-08-04 10:20:40,096 p=2473 u=root |  changed: [k8-node] => (item=80)
2020-08-04 10:20:40,680 p=2473 u=root |  changed: [k8-node] => (item=8080)
2020-08-04 10:20:40,685 p=2473 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-08-04 10:20:41,078 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:41,250 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:41,255 p=2473 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-08-04 10:20:41,736 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:41,796 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:41,802 p=2473 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] *************************************************************
2020-08-04 10:20:42,648 p=2473 u=root |  changed: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-04 10:20:42,703 p=2473 u=root |  changed: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-04 10:20:43,010 p=2473 u=root |  changed: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-04 10:20:43,067 p=2473 u=root |  changed: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-04 10:20:43,074 p=2473 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-08-04 10:20:43,473 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:43,481 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:43,485 p=2473 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-08-04 10:20:44,204 p=2473 u=root |  changed: [k8-master]
2020-08-04 10:20:44,214 p=2473 u=root |  changed: [k8-node]
2020-08-04 10:20:44,219 p=2473 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ***********************************************************
2020-08-04 10:20:45,576 p=2473 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "Unsupported parameters for (yum) module: disable_excludes Supported parameters include: allow_downgrade,conf_file,disable_gpg_check,disablerepo,enablerepo,exclude,install_repoquery,installroot,list,name,security,skip_broken,state,update_cache,validate_certs"}
2020-08-04 10:20:46,801 p=2473 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "Unsupported parameters for (yum) module: disable_excludes Supported parameters include: allow_downgrade,conf_file,disable_gpg_check,disablerepo,enablerepo,exclude,install_repoquery,installroot,list,name,security,skip_broken,state,update_cache,validate_certs"}
2020-08-04 10:20:46,803 p=2473 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-04 10:20:46,803 p=2473 u=root |  PLAY RECAP ***************************************************************************************************************************
2020-08-04 10:20:46,803 p=2473 u=root |  k8-master                  : ok=13   changed=11   unreachable=0    failed=1   
2020-08-04 10:20:46,803 p=2473 u=root |  k8-node                    : ok=13   changed=11   unreachable=0    failed=1   
2020-08-04 10:21:52,703 p=2840 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ************************************
2020-08-04 10:21:52,711 p=2840 u=root |  TASK [Gathering Facts] ***************************************************************************************************************
2020-08-04 10:21:53,979 p=2840 u=root |  ok: [k8-master]
2020-08-04 10:21:53,983 p=2840 u=root |  ok: [k8-node]
2020-08-04 10:21:53,988 p=2840 u=root |  TASK [Verifying if enough resources Present] *****************************************************************************************
2020-08-04 10:21:54,005 p=2840 u=root |  skipping: [k8-master]
2020-08-04 10:21:54,014 p=2840 u=root |  skipping: [k8-node]
2020-08-04 10:21:54,019 p=2840 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] ******************************************************************************************
2020-08-04 10:21:54,037 p=2840 u=root |  skipping: [k8-master]
2020-08-04 10:21:54,046 p=2840 u=root |  skipping: [k8-node]
2020-08-04 10:21:54,052 p=2840 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] ************************************************************************************
2020-08-04 10:21:54,501 p=2840 u=root |  changed: [k8-master]
2020-08-04 10:21:54,504 p=2840 u=root |  changed: [k8-node]
2020-08-04 10:21:54,509 p=2840 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] ***************************************************************************************
2020-08-04 10:21:54,527 p=2840 u=root |  skipping: [k8-master]
2020-08-04 10:21:54,533 p=2840 u=root |  skipping: [k8-node]
2020-08-04 10:21:54,539 p=2840 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] **************************************************************************
2020-08-04 10:21:54,594 p=2840 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-04 10:21:54,604 p=2840 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-04 10:21:54,610 p=2840 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] **************************************************************************
2020-08-04 10:21:55,415 p=2840 u=root |  ok: [k8-master]
2020-08-04 10:21:55,418 p=2840 u=root |  ok: [k8-node]
2020-08-04 10:21:55,423 p=2840 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] *****************************************************************************
2020-08-04 10:21:55,905 p=2840 u=root |  ok: [k8-master]
2020-08-04 10:21:55,906 p=2840 u=root |  ok: [k8-node]
2020-08-04 10:21:55,911 p=2840 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] *******************************************************************
2020-08-04 10:21:55,963 p=2840 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-04 10:21:55,964 p=2840 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-04 10:21:55,964 p=2840 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-04 10:21:55,964 p=2840 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-04 10:21:55,965 p=2840 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-04 10:21:55,966 p=2840 u=root |  skipping: [k8-node] => (item=80) 
2020-08-04 10:21:55,966 p=2840 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-04 10:21:56,611 p=2840 u=root |  ok: [k8-master] => (item=6443)
2020-08-04 10:21:57,190 p=2840 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-04 10:21:57,728 p=2840 u=root |  ok: [k8-master] => (item=10250)
2020-08-04 10:21:58,302 p=2840 u=root |  ok: [k8-master] => (item=10251)
2020-08-04 10:21:58,802 p=2840 u=root |  ok: [k8-master] => (item=10252)
2020-08-04 10:21:59,350 p=2840 u=root |  ok: [k8-master] => (item=80)
2020-08-04 10:21:59,896 p=2840 u=root |  ok: [k8-master] => (item=8080)
2020-08-04 10:21:59,902 p=2840 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ******************************************************************
2020-08-04 10:21:59,935 p=2840 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-04 10:21:59,936 p=2840 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-04 10:21:59,937 p=2840 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-04 10:21:59,948 p=2840 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-04 10:21:59,949 p=2840 u=root |  skipping: [k8-master] => (item=80) 
2020-08-04 10:21:59,949 p=2840 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-04 10:22:00,532 p=2840 u=root |  ok: [k8-node] => (item=10250)
2020-08-04 10:22:01,114 p=2840 u=root |  ok: [k8-node] => (item=10255)
2020-08-04 10:22:01,708 p=2840 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-04 10:22:02,305 p=2840 u=root |  ok: [k8-node] => (item=6783)
2020-08-04 10:22:02,871 p=2840 u=root |  ok: [k8-node] => (item=80)
2020-08-04 10:22:03,433 p=2840 u=root |  ok: [k8-node] => (item=8080)
2020-08-04 10:22:03,439 p=2840 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] ******************************************************************************
2020-08-04 10:22:03,827 p=2840 u=root |  changed: [k8-master]
2020-08-04 10:22:03,839 p=2840 u=root |  changed: [k8-node]
2020-08-04 10:22:03,844 p=2840 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] *********************************************************************
2020-08-04 10:22:03,869 p=2840 u=root |  skipping: [k8-master]
2020-08-04 10:22:03,872 p=2840 u=root |  skipping: [k8-node]
2020-08-04 10:22:03,879 p=2840 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] *************************************************************
2020-08-04 10:22:04,390 p=2840 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-04 10:22:04,432 p=2840 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-04 10:22:04,753 p=2840 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-04 10:22:04,760 p=2840 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-04 10:22:04,765 p=2840 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ***************************************************************
2020-08-04 10:22:05,144 p=2840 u=root |  changed: [k8-master]
2020-08-04 10:22:05,149 p=2840 u=root |  changed: [k8-node]
2020-08-04 10:22:05,154 p=2840 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] **************************************************************
2020-08-04 10:22:05,780 p=2840 u=root |  ok: [k8-master]
2020-08-04 10:22:05,800 p=2840 u=root |  ok: [k8-node]
2020-08-04 10:22:05,805 p=2840 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ***********************************************************
2020-08-04 10:22:09,028 p=2840 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "No package matching 'docker' found available, installed or updated", "rc": 126, "results": ["No package matching 'docker' found available, installed or updated"]}
2020-08-04 10:22:09,471 p=2840 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "No package matching 'docker' found available, installed or updated", "rc": 126, "results": ["No package matching 'docker' found available, installed or updated"]}
2020-08-04 10:22:09,473 p=2840 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-04 10:22:09,473 p=2840 u=root |  PLAY RECAP ***************************************************************************************************************************
2020-08-04 10:22:09,473 p=2840 u=root |  k8-master                  : ok=10   changed=3    unreachable=0    failed=1   
2020-08-04 10:22:09,474 p=2840 u=root |  k8-node                    : ok=10   changed=3    unreachable=0    failed=1   
2020-08-05 10:34:06,326 p=2509 u=root |  k8-node | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "192.168.122.1", 
            "192.168.16.11"
        ], 
        "ansible_all_ipv6_addresses": [
            "fe80::b591:2875:2005:b268", 
            "fe80::acff:e46f:9ca1:82cb"
        ], 
        "ansible_apparmor": {
            "status": "disabled"
        }, 
        "ansible_architecture": "x86_64", 
        "ansible_bios_date": "04/13/2018", 
        "ansible_bios_version": "6.00", 
        "ansible_cmdline": {
            "BOOT_IMAGE": "/vmlinuz-3.10.0-693.11.6.el7.x86_64", 
            "LANG": "en_US.UTF-8", 
            "quiet": true, 
            "rhgb": true, 
            "ro": true, 
            "root": "UUID=bbe9cc82-b48e-43cf-a1fe-25d218862baf"
        }, 
        "ansible_date_time": {
            "date": "2020-08-04", 
            "day": "04", 
            "epoch": "1596603845", 
            "hour": "22", 
            "iso8601": "2020-08-05T05:04:05Z", 
            "iso8601_basic": "20200804T220405864258", 
            "iso8601_basic_short": "20200804T220405", 
            "iso8601_micro": "2020-08-05T05:04:05.864346Z", 
            "minute": "04", 
            "month": "08", 
            "second": "05", 
            "time": "22:04:05", 
            "tz": "PDT", 
            "tz_offset": "-0700", 
            "weekday": "Tuesday", 
            "weekday_number": "2", 
            "weeknumber": "31", 
            "year": "2020"
        }, 
        "ansible_default_ipv4": {
            "address": "192.168.16.11", 
            "alias": "ens33", 
            "broadcast": "192.168.16.255", 
            "gateway": "192.168.16.140", 
            "interface": "ens33", 
            "macaddress": "00:50:56:23:3e:2c", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "192.168.16.0", 
            "type": "ether"
        }, 
        "ansible_default_ipv6": {}, 
        "ansible_device_links": {
            "ids": {
                "sr0": [
                    "ata-VMware_Virtual_SATA_CDRW_Drive_01000000000000000001"
                ]
            }, 
            "labels": {
                "sr0": [
                    "RHEL-7.4\\x20Server.x86_64"
                ]
            }, 
            "masters": {}, 
            "uuids": {
                "sda1": [
                    "f003a382-99d3-49ed-b010-fe986c169c1c"
                ], 
                "sda2": [
                    "82196a50-5d76-463b-a089-f80c854bc3ab"
                ], 
                "sda3": [
                    "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
                ], 
                "sr0": [
                    "2018-01-05-16-49-41-00"
                ]
            }
        }, 
        "ansible_devices": {
            "sda": {
                "holders": [], 
                "host": "SCSI storage controller: LSI Logic / Symbios Logic 53c1030 PCI-X Fusion-MPT Dual Ultra320 SCSI (rev 01)", 
                "links": {
                    "ids": [], 
                    "labels": [], 
                    "masters": [], 
                    "uuids": []
                }, 
                "model": "VMware Virtual S", 
                "partitions": {
                    "sda1": {
                        "holders": [], 
                        "links": {
                            "ids": [], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "f003a382-99d3-49ed-b010-fe986c169c1c"
                            ]
                        }, 
                        "sectors": "614400", 
                        "sectorsize": 512, 
                        "size": "300.00 MB", 
                        "start": "2048", 
                        "uuid": "f003a382-99d3-49ed-b010-fe986c169c1c"
                    }, 
                    "sda2": {
                        "holders": [], 
                        "links": {
                            "ids": [], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "82196a50-5d76-463b-a089-f80c854bc3ab"
                            ]
                        }, 
                        "sectors": "4194304", 
                        "sectorsize": 512, 
                        "size": "2.00 GB", 
                        "start": "616448", 
                        "uuid": "82196a50-5d76-463b-a089-f80c854bc3ab"
                    }, 
                    "sda3": {
                        "holders": [], 
                        "links": {
                            "ids": [], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
                            ]
                        }, 
                        "sectors": "37132288", 
                        "sectorsize": 512, 
                        "size": "17.71 GB", 
                        "start": "4810752", 
                        "uuid": "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
                    }
                }, 
                "removable": "0", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "deadline", 
                "sectors": "41943040", 
                "sectorsize": "512", 
                "size": "20.00 GB", 
                "support_discard": "0", 
                "vendor": "VMware,", 
                "virtual": 1
            }, 
            "sr0": {
                "holders": [], 
                "host": "SATA controller: VMware SATA AHCI controller", 
                "links": {
                    "ids": [
                        "ata-VMware_Virtual_SATA_CDRW_Drive_01000000000000000001"
                    ], 
                    "labels": [
                        "RHEL-7.4\\x20Server.x86_64"
                    ], 
                    "masters": [], 
                    "uuids": [
                        "2018-01-05-16-49-41-00"
                    ]
                }, 
                "model": "VMware SATA CD01", 
                "partitions": {}, 
                "removable": "1", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "cfq", 
                "sectors": "8544256", 
                "sectorsize": "2048", 
                "size": "16.30 GB", 
                "support_discard": "0", 
                "vendor": "NECVMWar", 
                "virtual": 1
            }
        }, 
        "ansible_distribution": "RedHat", 
        "ansible_distribution_file_parsed": true, 
        "ansible_distribution_file_path": "/etc/redhat-release", 
        "ansible_distribution_file_variety": "RedHat", 
        "ansible_distribution_major_version": "7", 
        "ansible_distribution_release": "Maipo", 
        "ansible_distribution_version": "7.4", 
        "ansible_dns": {
            "nameservers": [
                "192.168.16.140"
            ], 
            "search": [
                "technix.com"
            ]
        }, 
        "ansible_domain": "technix.com", 
        "ansible_effective_group_id": 0, 
        "ansible_effective_user_id": 0, 
        "ansible_ens33": {
            "active": true, 
            "device": "ens33", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_mpls_segmentation": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "192.168.16.11", 
                "broadcast": "192.168.16.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.16.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::b591:2875:2005:b268", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "00:50:56:23:3e:2c", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:02:01.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "ansible_env": {
            "HOME": "/root", 
            "LANG": "en_US.UTF-8", 
            "LESSOPEN": "||/usr/bin/lesspipe.sh %s", 
            "LOGNAME": "root", 
            "LS_COLORS": "rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:", 
            "MAIL": "/var/mail/root", 
            "PATH": "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin", 
            "PWD": "/root", 
            "SHELL": "/bin/bash", 
            "SHLVL": "2", 
            "SSH_CLIENT": "192.168.16.93 48634 22", 
            "SSH_CONNECTION": "192.168.16.93 48634 192.168.16.11 22", 
            "SSH_TTY": "/dev/pts/2", 
            "TERM": "xterm", 
            "USER": "root", 
            "XDG_DATA_DIRS": "/root/.local/share/flatpak/exports/share/:/var/lib/flatpak/exports/share/:/usr/local/share/:/usr/share/", 
            "XDG_RUNTIME_DIR": "/run/user/0", 
            "XDG_SESSION_ID": "7", 
            "_": "/usr/bin/python"
        }, 
        "ansible_fips": false, 
        "ansible_form_factor": "Other", 
        "ansible_fqdn": "k8-node.technix.com", 
        "ansible_hostname": "k8-node", 
        "ansible_interfaces": [
            "lo", 
            "virbr0", 
            "virbr0-nic", 
            "ens33"
        ], 
        "ansible_kernel": "3.10.0-693.11.6.el7.x86_64", 
        "ansible_lo": {
            "active": true, 
            "device": "lo", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "on [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "on [fixed]", 
                "netns_local": "on [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "on [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on [fixed]", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "on [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "on [fixed]", 
                "tx_mpls_segmentation": "off [fixed]", 
                "tx_nocache_copy": "off [fixed]", 
                "tx_scatter_gather": "on [fixed]", 
                "tx_scatter_gather_fraglist": "on [fixed]", 
                "tx_sctp_segmentation": "on", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "on", 
                "tx_tcp_ecn_segmentation": "on", 
                "tx_tcp_mangleid_segmentation": "on", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "off [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "on", 
                "vlan_challenged": "on [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "127.0.0.1", 
                "broadcast": "host", 
                "netmask": "255.0.0.0", 
                "network": "127.0.0.0"
            }, 
            "ipv6": [
                {
                    "address": "::1", 
                    "prefix": "128", 
                    "scope": "host"
                }
            ], 
            "mtu": 65536, 
            "promisc": false, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "loopback"
        }, 
        "ansible_local": {}, 
        "ansible_lsb": {}, 
        "ansible_lvm": {
            "lvs": {}, 
            "pvs": {}, 
            "vgs": {}
        }, 
        "ansible_machine": "x86_64", 
        "ansible_machine_id": "3f9f575dfe4c414da1795adf8fa947d2", 
        "ansible_memfree_mb": 1352, 
        "ansible_memory_mb": {
            "nocache": {
                "free": 1587, 
                "used": 396
            }, 
            "real": {
                "free": 1352, 
                "total": 1983, 
                "used": 631
            }, 
            "swap": {
                "cached": 0, 
                "free": 0, 
                "total": 0, 
                "used": 0
            }
        }, 
        "ansible_memtotal_mb": 1983, 
        "ansible_mounts": [
            {
                "block_available": 3754653, 
                "block_size": 4096, 
                "block_total": 4638976, 
                "block_used": 884323, 
                "device": "/dev/sda3", 
                "fstype": "xfs", 
                "inode_available": 9145984, 
                "inode_total": 9283072, 
                "inode_used": 137088, 
                "mount": "/", 
                "options": "rw,relatime,attr2,inode64,noquota", 
                "size_available": 15379058688, 
                "size_total": 19001245696, 
                "uuid": "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
            }, 
            {
                "block_available": 39799, 
                "block_size": 4096, 
                "block_total": 75945, 
                "block_used": 36146, 
                "device": "/dev/sda1", 
                "fstype": "xfs", 
                "inode_available": 153275, 
                "inode_total": 153600, 
                "inode_used": 325, 
                "mount": "/boot", 
                "options": "rw,relatime,attr2,inode64,noquota", 
                "size_available": 163016704, 
                "size_total": 311070720, 
                "uuid": "f003a382-99d3-49ed-b010-fe986c169c1c"
            }
        ], 
        "ansible_nodename": "k8-node.technix.com", 
        "ansible_os_family": "RedHat", 
        "ansible_pkg_mgr": "yum", 
        "ansible_processor": [
            "0", 
            "GenuineIntel", 
            "Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz", 
            "1", 
            "GenuineIntel", 
            "Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz"
        ], 
        "ansible_processor_cores": 1, 
        "ansible_processor_count": 2, 
        "ansible_processor_threads_per_core": 1, 
        "ansible_processor_vcpus": 2, 
        "ansible_product_name": "VMware Virtual Platform", 
        "ansible_product_serial": "VMware-56 4d 4f 70 e4 6b 96 45-c8 cb 09 06 cf 0a c0 99", 
        "ansible_product_uuid": "704F4D56-6BE4-4596-C8CB-0906CF0AC099", 
        "ansible_product_version": "None", 
        "ansible_python": {
            "executable": "/usr/bin/python", 
            "has_sslcontext": true, 
            "type": "CPython", 
            "version": {
                "major": 2, 
                "micro": 5, 
                "minor": 7, 
                "releaselevel": "final", 
                "serial": 0
            }, 
            "version_info": [
                2, 
                7, 
                5, 
                "final", 
                0
            ]
        }, 
        "ansible_python_version": "2.7.5", 
        "ansible_real_group_id": 0, 
        "ansible_real_user_id": 0, 
        "ansible_selinux": {
            "status": "disabled"
        }, 
        "ansible_selinux_python_present": true, 
        "ansible_service_mgr": "systemd", 
        "ansible_ssh_host_key_ecdsa_public": "AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBGW02Mm7ApWQmG5b0MKh4b6RV8/79/uGxhlwaKD1GPa/t1RNqv8XR+fXR5GN8LciQfxzi8FKfQzpDJ5jCXl4Oe4=", 
        "ansible_ssh_host_key_ed25519_public": "AAAAC3NzaC1lZDI1NTE5AAAAIGWcyBmE99tYczPVLH4BLApSEG2si9pfnFnwcUaAJaOg", 
        "ansible_ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABAQDOOJs0CrmUDvjWrgre7s4pbF6za7AeRHCI0oQpJLB7khpXzkxJvoCD/IIRx0V3K75lcSxG9OIKmwdP067AMEBeBnqDvhTYkZKlwwasQeTO+6LfQdQyXX2JFX/hOX1HHN5JQUQD+Xcfz+jwcMo7SoyFimC4AWGPoFVYX6bJ81o7fTiJiXjT5OaNDvPMiZBD2ViQ8KOLK4iv3z9XJs7Gtj3/m7G3sfqzz4HxI8ViKxEX+KJ0E5s2Ff/AwVdbjz3EMX4TLRdoyhEVbZ7wGy140C6MDOQMPvzU2XHXPrCpvZX9odE0ROS/ZUvXY51cmAhK9fqM13ACE1KRZ2xpr0Qfwkjx", 
        "ansible_swapfree_mb": 0, 
        "ansible_swaptotal_mb": 0, 
        "ansible_system": "Linux", 
        "ansible_system_capabilities": [
            "cap_chown", 
            "cap_dac_override", 
            "cap_dac_read_search", 
            "cap_fowner", 
            "cap_fsetid", 
            "cap_kill", 
            "cap_setgid", 
            "cap_setuid", 
            "cap_setpcap", 
            "cap_linux_immutable", 
            "cap_net_bind_service", 
            "cap_net_broadcast", 
            "cap_net_admin", 
            "cap_net_raw", 
            "cap_ipc_lock", 
            "cap_ipc_owner", 
            "cap_sys_module", 
            "cap_sys_rawio", 
            "cap_sys_chroot", 
            "cap_sys_ptrace", 
            "cap_sys_pacct", 
            "cap_sys_admin", 
            "cap_sys_boot", 
            "cap_sys_nice", 
            "cap_sys_resource", 
            "cap_sys_time", 
            "cap_sys_tty_config", 
            "cap_mknod", 
            "cap_lease", 
            "cap_audit_write", 
            "cap_audit_control", 
            "cap_setfcap", 
            "cap_mac_override", 
            "cap_mac_admin", 
            "cap_syslog", 
            "35", 
            "36+ep"
        ], 
        "ansible_system_capabilities_enforced": "True", 
        "ansible_system_vendor": "VMware, Inc.", 
        "ansible_uptime_seconds": 1859, 
        "ansible_user_dir": "/root", 
        "ansible_user_gecos": "root", 
        "ansible_user_gid": 0, 
        "ansible_user_id": "root", 
        "ansible_user_shell": "/bin/bash", 
        "ansible_user_uid": 0, 
        "ansible_userspace_architecture": "x86_64", 
        "ansible_userspace_bits": "64", 
        "ansible_virbr0": {
            "active": false, 
            "device": "virbr0", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [requested on]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "on [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "off [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [requested on]", 
                "tx_gre_csum_segmentation": "on", 
                "tx_gre_segmentation": "on", 
                "tx_gso_partial": "on", 
                "tx_gso_robust": "off [requested on]", 
                "tx_ipip_segmentation": "on", 
                "tx_lockless": "on [fixed]", 
                "tx_mpls_segmentation": "on", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "on", 
                "tx_sctp_segmentation": "off [requested on]", 
                "tx_sit_segmentation": "on", 
                "tx_tcp6_segmentation": "on", 
                "tx_tcp_ecn_segmentation": "on", 
                "tx_tcp_mangleid_segmentation": "on", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "on", 
                "tx_udp_tnl_segmentation": "on", 
                "tx_vlan_offload": "on", 
                "tx_vlan_stag_hw_insert": "on", 
                "udp_fragmentation_offload": "off [requested on]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "id": "8000.525400a9d87b", 
            "interfaces": [
                "virbr0-nic"
            ], 
            "ipv4": {
                "address": "192.168.122.1", 
                "broadcast": "192.168.122.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.122.0"
            }, 
            "macaddress": "52:54:00:a9:d8:7b", 
            "mtu": 1500, 
            "promisc": false, 
            "stp": true, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "bridge"
        }, 
        "ansible_virbr0_nic": {
            "active": false, 
            "device": "virbr0-nic", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "off [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "off", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "off [requested on]", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "off", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "on [fixed]", 
                "tx_mpls_segmentation": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "on", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [requested on]", 
                "tx_tcp_ecn_segmentation": "off [requested on]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "off [requested on]", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on", 
                "tx_vlan_stag_hw_insert": "on", 
                "udp_fragmentation_offload": "off [requested on]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "macaddress": "52:54:00:a9:d8:7b", 
            "mtu": 1500, 
            "promisc": true, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "ansible_virtualization_role": "guest", 
        "ansible_virtualization_type": "VMware", 
        "gather_subset": [
            "all"
        ], 
        "module_setup": true
    }, 
    "changed": false, 
    "failed": false
}
2020-08-05 10:34:14,588 p=2531 u=root |  k8-node | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "192.168.122.1", 
            "192.168.16.11"
        ], 
        "ansible_all_ipv6_addresses": [
            "fe80::b591:2875:2005:b268", 
            "fe80::acff:e46f:9ca1:82cb"
        ], 
        "ansible_apparmor": {
            "status": "disabled"
        }, 
        "ansible_architecture": "x86_64", 
        "ansible_bios_date": "04/13/2018", 
        "ansible_bios_version": "6.00", 
        "ansible_cmdline": {
            "BOOT_IMAGE": "/vmlinuz-3.10.0-693.11.6.el7.x86_64", 
            "LANG": "en_US.UTF-8", 
            "quiet": true, 
            "rhgb": true, 
            "ro": true, 
            "root": "UUID=bbe9cc82-b48e-43cf-a1fe-25d218862baf"
        }, 
        "ansible_date_time": {
            "date": "2020-08-04", 
            "day": "04", 
            "epoch": "1596603854", 
            "hour": "22", 
            "iso8601": "2020-08-05T05:04:14Z", 
            "iso8601_basic": "20200804T220414131432", 
            "iso8601_basic_short": "20200804T220414", 
            "iso8601_micro": "2020-08-05T05:04:14.131499Z", 
            "minute": "04", 
            "month": "08", 
            "second": "14", 
            "time": "22:04:14", 
            "tz": "PDT", 
            "tz_offset": "-0700", 
            "weekday": "Tuesday", 
            "weekday_number": "2", 
            "weeknumber": "31", 
            "year": "2020"
        }, 
        "ansible_default_ipv4": {
            "address": "192.168.16.11", 
            "alias": "ens33", 
            "broadcast": "192.168.16.255", 
            "gateway": "192.168.16.140", 
            "interface": "ens33", 
            "macaddress": "00:50:56:23:3e:2c", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "192.168.16.0", 
            "type": "ether"
        }, 
        "ansible_default_ipv6": {}, 
        "ansible_device_links": {
            "ids": {
                "sr0": [
                    "ata-VMware_Virtual_SATA_CDRW_Drive_01000000000000000001"
                ]
            }, 
            "labels": {
                "sr0": [
                    "RHEL-7.4\\x20Server.x86_64"
                ]
            }, 
            "masters": {}, 
            "uuids": {
                "sda1": [
                    "f003a382-99d3-49ed-b010-fe986c169c1c"
                ], 
                "sda2": [
                    "82196a50-5d76-463b-a089-f80c854bc3ab"
                ], 
                "sda3": [
                    "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
                ], 
                "sr0": [
                    "2018-01-05-16-49-41-00"
                ]
            }
        }, 
        "ansible_devices": {
            "sda": {
                "holders": [], 
                "host": "SCSI storage controller: LSI Logic / Symbios Logic 53c1030 PCI-X Fusion-MPT Dual Ultra320 SCSI (rev 01)", 
                "links": {
                    "ids": [], 
                    "labels": [], 
                    "masters": [], 
                    "uuids": []
                }, 
                "model": "VMware Virtual S", 
                "partitions": {
                    "sda1": {
                        "holders": [], 
                        "links": {
                            "ids": [], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "f003a382-99d3-49ed-b010-fe986c169c1c"
                            ]
                        }, 
                        "sectors": "614400", 
                        "sectorsize": 512, 
                        "size": "300.00 MB", 
                        "start": "2048", 
                        "uuid": "f003a382-99d3-49ed-b010-fe986c169c1c"
                    }, 
                    "sda2": {
                        "holders": [], 
                        "links": {
                            "ids": [], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "82196a50-5d76-463b-a089-f80c854bc3ab"
                            ]
                        }, 
                        "sectors": "4194304", 
                        "sectorsize": 512, 
                        "size": "2.00 GB", 
                        "start": "616448", 
                        "uuid": "82196a50-5d76-463b-a089-f80c854bc3ab"
                    }, 
                    "sda3": {
                        "holders": [], 
                        "links": {
                            "ids": [], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
                            ]
                        }, 
                        "sectors": "37132288", 
                        "sectorsize": 512, 
                        "size": "17.71 GB", 
                        "start": "4810752", 
                        "uuid": "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
                    }
                }, 
                "removable": "0", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "deadline", 
                "sectors": "41943040", 
                "sectorsize": "512", 
                "size": "20.00 GB", 
                "support_discard": "0", 
                "vendor": "VMware,", 
                "virtual": 1
            }, 
            "sr0": {
                "holders": [], 
                "host": "SATA controller: VMware SATA AHCI controller", 
                "links": {
                    "ids": [
                        "ata-VMware_Virtual_SATA_CDRW_Drive_01000000000000000001"
                    ], 
                    "labels": [
                        "RHEL-7.4\\x20Server.x86_64"
                    ], 
                    "masters": [], 
                    "uuids": [
                        "2018-01-05-16-49-41-00"
                    ]
                }, 
                "model": "VMware SATA CD01", 
                "partitions": {}, 
                "removable": "1", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "cfq", 
                "sectors": "8544256", 
                "sectorsize": "2048", 
                "size": "16.30 GB", 
                "support_discard": "0", 
                "vendor": "NECVMWar", 
                "virtual": 1
            }
        }, 
        "ansible_distribution": "RedHat", 
        "ansible_distribution_file_parsed": true, 
        "ansible_distribution_file_path": "/etc/redhat-release", 
        "ansible_distribution_file_variety": "RedHat", 
        "ansible_distribution_major_version": "7", 
        "ansible_distribution_release": "Maipo", 
        "ansible_distribution_version": "7.4", 
        "ansible_dns": {
            "nameservers": [
                "192.168.16.140"
            ], 
            "search": [
                "technix.com"
            ]
        }, 
        "ansible_domain": "technix.com", 
        "ansible_effective_group_id": 0, 
        "ansible_effective_user_id": 0, 
        "ansible_ens33": {
            "active": true, 
            "device": "ens33", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_mpls_segmentation": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "192.168.16.11", 
                "broadcast": "192.168.16.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.16.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::b591:2875:2005:b268", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "00:50:56:23:3e:2c", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:02:01.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "ansible_env": {
            "HOME": "/root", 
            "LANG": "en_US.UTF-8", 
            "LESSOPEN": "||/usr/bin/lesspipe.sh %s", 
            "LOGNAME": "root", 
            "LS_COLORS": "rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:", 
            "MAIL": "/var/mail/root", 
            "PATH": "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin", 
            "PWD": "/root", 
            "SHELL": "/bin/bash", 
            "SHLVL": "2", 
            "SSH_CLIENT": "192.168.16.93 48634 22", 
            "SSH_CONNECTION": "192.168.16.93 48634 192.168.16.11 22", 
            "SSH_TTY": "/dev/pts/2", 
            "TERM": "xterm", 
            "USER": "root", 
            "XDG_DATA_DIRS": "/root/.local/share/flatpak/exports/share/:/var/lib/flatpak/exports/share/:/usr/local/share/:/usr/share/", 
            "XDG_RUNTIME_DIR": "/run/user/0", 
            "XDG_SESSION_ID": "7", 
            "_": "/usr/bin/python"
        }, 
        "ansible_fips": false, 
        "ansible_form_factor": "Other", 
        "ansible_fqdn": "k8-node.technix.com", 
        "ansible_hostname": "k8-node", 
        "ansible_interfaces": [
            "lo", 
            "virbr0", 
            "virbr0-nic", 
            "ens33"
        ], 
        "ansible_kernel": "3.10.0-693.11.6.el7.x86_64", 
        "ansible_lo": {
            "active": true, 
            "device": "lo", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "on [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "on [fixed]", 
                "netns_local": "on [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "on [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on [fixed]", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "on [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "on [fixed]", 
                "tx_mpls_segmentation": "off [fixed]", 
                "tx_nocache_copy": "off [fixed]", 
                "tx_scatter_gather": "on [fixed]", 
                "tx_scatter_gather_fraglist": "on [fixed]", 
                "tx_sctp_segmentation": "on", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "on", 
                "tx_tcp_ecn_segmentation": "on", 
                "tx_tcp_mangleid_segmentation": "on", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "off [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "on", 
                "vlan_challenged": "on [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "127.0.0.1", 
                "broadcast": "host", 
                "netmask": "255.0.0.0", 
                "network": "127.0.0.0"
            }, 
            "ipv6": [
                {
                    "address": "::1", 
                    "prefix": "128", 
                    "scope": "host"
                }
            ], 
            "mtu": 65536, 
            "promisc": false, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "loopback"
        }, 
        "ansible_local": {}, 
        "ansible_lsb": {}, 
        "ansible_lvm": {
            "lvs": {}, 
            "pvs": {}, 
            "vgs": {}
        }, 
        "ansible_machine": "x86_64", 
        "ansible_machine_id": "3f9f575dfe4c414da1795adf8fa947d2", 
        "ansible_memfree_mb": 1348, 
        "ansible_memory_mb": {
            "nocache": {
                "free": 1586, 
                "used": 397
            }, 
            "real": {
                "free": 1348, 
                "total": 1983, 
                "used": 635
            }, 
            "swap": {
                "cached": 0, 
                "free": 0, 
                "total": 0, 
                "used": 0
            }
        }, 
        "ansible_memtotal_mb": 1983, 
        "ansible_mounts": [
            {
                "block_available": 3754653, 
                "block_size": 4096, 
                "block_total": 4638976, 
                "block_used": 884323, 
                "device": "/dev/sda3", 
                "fstype": "xfs", 
                "inode_available": 9145984, 
                "inode_total": 9283072, 
                "inode_used": 137088, 
                "mount": "/", 
                "options": "rw,relatime,attr2,inode64,noquota", 
                "size_available": 15379058688, 
                "size_total": 19001245696, 
                "uuid": "bbe9cc82-b48e-43cf-a1fe-25d218862baf"
            }, 
            {
                "block_available": 39799, 
                "block_size": 4096, 
                "block_total": 75945, 
                "block_used": 36146, 
                "device": "/dev/sda1", 
                "fstype": "xfs", 
                "inode_available": 153275, 
                "inode_total": 153600, 
                "inode_used": 325, 
                "mount": "/boot", 
                "options": "rw,relatime,attr2,inode64,noquota", 
                "size_available": 163016704, 
                "size_total": 311070720, 
                "uuid": "f003a382-99d3-49ed-b010-fe986c169c1c"
            }
        ], 
        "ansible_nodename": "k8-node.technix.com", 
        "ansible_os_family": "RedHat", 
        "ansible_pkg_mgr": "yum", 
        "ansible_processor": [
            "0", 
            "GenuineIntel", 
            "Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz", 
            "1", 
            "GenuineIntel", 
            "Intel(R) Xeon(R) CPU E3-1225 v3 @ 3.20GHz"
        ], 
        "ansible_processor_cores": 1, 
        "ansible_processor_count": 2, 
        "ansible_processor_threads_per_core": 1, 
        "ansible_processor_vcpus": 2, 
        "ansible_product_name": "VMware Virtual Platform", 
        "ansible_product_serial": "VMware-56 4d 4f 70 e4 6b 96 45-c8 cb 09 06 cf 0a c0 99", 
        "ansible_product_uuid": "704F4D56-6BE4-4596-C8CB-0906CF0AC099", 
        "ansible_product_version": "None", 
        "ansible_python": {
            "executable": "/usr/bin/python", 
            "has_sslcontext": true, 
            "type": "CPython", 
            "version": {
                "major": 2, 
                "micro": 5, 
                "minor": 7, 
                "releaselevel": "final", 
                "serial": 0
            }, 
            "version_info": [
                2, 
                7, 
                5, 
                "final", 
                0
            ]
        }, 
        "ansible_python_version": "2.7.5", 
        "ansible_real_group_id": 0, 
        "ansible_real_user_id": 0, 
        "ansible_selinux": {
            "status": "disabled"
        }, 
        "ansible_selinux_python_present": true, 
        "ansible_service_mgr": "systemd", 
        "ansible_ssh_host_key_ecdsa_public": "AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBGW02Mm7ApWQmG5b0MKh4b6RV8/79/uGxhlwaKD1GPa/t1RNqv8XR+fXR5GN8LciQfxzi8FKfQzpDJ5jCXl4Oe4=", 
        "ansible_ssh_host_key_ed25519_public": "AAAAC3NzaC1lZDI1NTE5AAAAIGWcyBmE99tYczPVLH4BLApSEG2si9pfnFnwcUaAJaOg", 
        "ansible_ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABAQDOOJs0CrmUDvjWrgre7s4pbF6za7AeRHCI0oQpJLB7khpXzkxJvoCD/IIRx0V3K75lcSxG9OIKmwdP067AMEBeBnqDvhTYkZKlwwasQeTO+6LfQdQyXX2JFX/hOX1HHN5JQUQD+Xcfz+jwcMo7SoyFimC4AWGPoFVYX6bJ81o7fTiJiXjT5OaNDvPMiZBD2ViQ8KOLK4iv3z9XJs7Gtj3/m7G3sfqzz4HxI8ViKxEX+KJ0E5s2Ff/AwVdbjz3EMX4TLRdoyhEVbZ7wGy140C6MDOQMPvzU2XHXPrCpvZX9odE0ROS/ZUvXY51cmAhK9fqM13ACE1KRZ2xpr0Qfwkjx", 
        "ansible_swapfree_mb": 0, 
        "ansible_swaptotal_mb": 0, 
        "ansible_system": "Linux", 
        "ansible_system_capabilities": [
            "cap_chown", 
            "cap_dac_override", 
            "cap_dac_read_search", 
            "cap_fowner", 
            "cap_fsetid", 
            "cap_kill", 
            "cap_setgid", 
            "cap_setuid", 
            "cap_setpcap", 
            "cap_linux_immutable", 
            "cap_net_bind_service", 
            "cap_net_broadcast", 
            "cap_net_admin", 
            "cap_net_raw", 
            "cap_ipc_lock", 
            "cap_ipc_owner", 
            "cap_sys_module", 
            "cap_sys_rawio", 
            "cap_sys_chroot", 
            "cap_sys_ptrace", 
            "cap_sys_pacct", 
            "cap_sys_admin", 
            "cap_sys_boot", 
            "cap_sys_nice", 
            "cap_sys_resource", 
            "cap_sys_time", 
            "cap_sys_tty_config", 
            "cap_mknod", 
            "cap_lease", 
            "cap_audit_write", 
            "cap_audit_control", 
            "cap_setfcap", 
            "cap_mac_override", 
            "cap_mac_admin", 
            "cap_syslog", 
            "35", 
            "36+ep"
        ], 
        "ansible_system_capabilities_enforced": "True", 
        "ansible_system_vendor": "VMware, Inc.", 
        "ansible_uptime_seconds": 1868, 
        "ansible_user_dir": "/root", 
        "ansible_user_gecos": "root", 
        "ansible_user_gid": 0, 
        "ansible_user_id": "root", 
        "ansible_user_shell": "/bin/bash", 
        "ansible_user_uid": 0, 
        "ansible_userspace_architecture": "x86_64", 
        "ansible_userspace_bits": "64", 
        "ansible_virbr0": {
            "active": false, 
            "device": "virbr0", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [requested on]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "on [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "off [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [requested on]", 
                "tx_gre_csum_segmentation": "on", 
                "tx_gre_segmentation": "on", 
                "tx_gso_partial": "on", 
                "tx_gso_robust": "off [requested on]", 
                "tx_ipip_segmentation": "on", 
                "tx_lockless": "on [fixed]", 
                "tx_mpls_segmentation": "on", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "on", 
                "tx_sctp_segmentation": "off [requested on]", 
                "tx_sit_segmentation": "on", 
                "tx_tcp6_segmentation": "on", 
                "tx_tcp_ecn_segmentation": "on", 
                "tx_tcp_mangleid_segmentation": "on", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "on", 
                "tx_udp_tnl_segmentation": "on", 
                "tx_vlan_offload": "on", 
                "tx_vlan_stag_hw_insert": "on", 
                "udp_fragmentation_offload": "off [requested on]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "id": "8000.525400a9d87b", 
            "interfaces": [
                "virbr0-nic"
            ], 
            "ipv4": {
                "address": "192.168.122.1", 
                "broadcast": "192.168.122.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.122.0"
            }, 
            "macaddress": "52:54:00:a9:d8:7b", 
            "mtu": 1500, 
            "promisc": false, 
            "stp": true, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "bridge"
        }, 
        "ansible_virbr0_nic": {
            "active": false, 
            "device": "virbr0-nic", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "off [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "off", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "off [requested on]", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "off", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "on [fixed]", 
                "tx_mpls_segmentation": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "on", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [requested on]", 
                "tx_tcp_ecn_segmentation": "off [requested on]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "off [requested on]", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on", 
                "tx_vlan_stag_hw_insert": "on", 
                "udp_fragmentation_offload": "off [requested on]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "macaddress": "52:54:00:a9:d8:7b", 
            "mtu": 1500, 
            "promisc": true, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "ansible_virtualization_role": "guest", 
        "ansible_virtualization_type": "VMware", 
        "gather_subset": [
            "all"
        ], 
        "module_setup": true
    }, 
    "changed": false, 
    "failed": false
}
2020-08-05 10:39:40,211 p=2964 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***
2020-08-05 10:39:40,218 p=2964 u=root |  TASK [Gathering Facts] ************************************************************
2020-08-05 10:39:42,255 p=2964 u=root |  ok: [k8-node]
2020-08-05 10:39:42,892 p=2964 u=root |  ok: [k8-master]
2020-08-05 10:39:42,910 p=2964 u=root |  TASK [Verifying if enough resources Present] **************************************
2020-08-05 10:39:42,927 p=2964 u=root |  skipping: [k8-master]
2020-08-05 10:39:42,934 p=2964 u=root |  skipping: [k8-node]
2020-08-05 10:39:42,939 p=2964 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] ***************************************
2020-08-05 10:39:42,955 p=2964 u=root |  skipping: [k8-master]
2020-08-05 10:39:42,964 p=2964 u=root |  skipping: [k8-node]
2020-08-05 10:39:42,968 p=2964 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] *********************************
2020-08-05 10:39:43,469 p=2964 u=root |  changed: [k8-master]
2020-08-05 10:39:43,490 p=2964 u=root |  changed: [k8-node]
2020-08-05 10:39:43,495 p=2964 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] ************************************
2020-08-05 10:39:43,512 p=2964 u=root |  skipping: [k8-master]
2020-08-05 10:39:43,520 p=2964 u=root |  skipping: [k8-node]
2020-08-05 10:39:43,526 p=2964 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] ***********************
2020-08-05 10:39:43,581 p=2964 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:39:43,591 p=2964 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:39:43,597 p=2964 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ***********************
2020-08-05 10:39:44,498 p=2964 u=root |  ok: [k8-master]
2020-08-05 10:39:44,521 p=2964 u=root |  ok: [k8-node]
2020-08-05 10:39:44,526 p=2964 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] **************************
2020-08-05 10:39:45,027 p=2964 u=root |  ok: [k8-master]
2020-08-05 10:39:45,041 p=2964 u=root |  ok: [k8-node]
2020-08-05 10:39:45,046 p=2964 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ****************
2020-08-05 10:39:45,119 p=2964 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 10:39:45,119 p=2964 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 10:39:45,119 p=2964 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 10:39:45,120 p=2964 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 10:39:45,120 p=2964 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 10:39:45,120 p=2964 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 10:39:45,120 p=2964 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 10:39:45,794 p=2964 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 10:39:46,329 p=2964 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 10:39:46,881 p=2964 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 10:39:47,410 p=2964 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 10:39:47,936 p=2964 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 10:39:48,476 p=2964 u=root |  ok: [k8-master] => (item=80)
2020-08-05 10:39:49,005 p=2964 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 10:39:49,010 p=2964 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ***************
2020-08-05 10:39:49,047 p=2964 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 10:39:49,047 p=2964 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 10:39:49,048 p=2964 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 10:39:49,048 p=2964 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 10:39:49,048 p=2964 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 10:39:49,048 p=2964 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 10:39:49,657 p=2964 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 10:39:50,221 p=2964 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 10:39:50,746 p=2964 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 10:39:51,314 p=2964 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 10:39:51,861 p=2964 u=root |  ok: [k8-node] => (item=80)
2020-08-05 10:39:52,408 p=2964 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 10:39:52,413 p=2964 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] ***************************
2020-08-05 10:39:52,774 p=2964 u=root |  changed: [k8-master]
2020-08-05 10:39:52,786 p=2964 u=root |  changed: [k8-node]
2020-08-05 10:39:52,790 p=2964 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ******************
2020-08-05 10:39:53,176 p=2964 u=root |  changed: [k8-node]
2020-08-05 10:39:53,186 p=2964 u=root |  changed: [k8-master]
2020-08-05 10:39:53,190 p=2964 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] **********
2020-08-05 10:39:53,680 p=2964 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:39:53,704 p=2964 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:39:54,035 p=2964 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:39:54,053 p=2964 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:39:54,058 p=2964 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ************
2020-08-05 10:39:54,410 p=2964 u=root |  changed: [k8-master]
2020-08-05 10:39:54,431 p=2964 u=root |  changed: [k8-node]
2020-08-05 10:39:54,436 p=2964 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ***********
2020-08-05 10:39:55,090 p=2964 u=root |  ok: [k8-node]
2020-08-05 10:39:55,103 p=2964 u=root |  ok: [k8-master]
2020-08-05 10:39:55,108 p=2964 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ****
2020-08-05 10:39:55,187 p=2964 u=root |  An exception occurred during task execution. To see the full traceback, use -vvv. The error was: 	/opt/python/ansible/kubernetesCluster/extraRepo
2020-08-05 10:39:55,188 p=2964 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "Could not find or access 'extraRepo'\nSearched in:\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/files/extraRepo\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/extraRepo\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/tasks/files/extraRepo\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/tasks/extraRepo\n\t/opt/python/ansible/kubernetesCluster/files/extraRepo\n\t/opt/python/ansible/kubernetesCluster/extraRepo"}
2020-08-05 10:39:55,190 p=2964 u=root |  An exception occurred during task execution. To see the full traceback, use -vvv. The error was: 	/opt/python/ansible/kubernetesCluster/extraRepo
2020-08-05 10:39:55,191 p=2964 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "Could not find or access 'extraRepo'\nSearched in:\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/files/extraRepo\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/extraRepo\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/tasks/files/extraRepo\n\t/opt/python/ansible/kubernetesCluster/deploy_kubernetes/tasks/extraRepo\n\t/opt/python/ansible/kubernetesCluster/files/extraRepo\n\t/opt/python/ansible/kubernetesCluster/extraRepo"}
2020-08-05 10:39:55,192 p=2964 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-05 10:39:55,192 p=2964 u=root |  PLAY RECAP ************************************************************************
2020-08-05 10:39:55,192 p=2964 u=root |  k8-master                  : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 10:39:55,193 p=2964 u=root |  k8-node                    : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 10:44:24,073 p=3297 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***
2020-08-05 10:44:24,080 p=3297 u=root |  TASK [Gathering Facts] ************************************************************
2020-08-05 10:44:25,058 p=3297 u=root |  ok: [k8-master]
2020-08-05 10:44:25,070 p=3297 u=root |  ok: [k8-node]
2020-08-05 10:44:25,075 p=3297 u=root |  TASK [Verifying if enough resources Present] **************************************
2020-08-05 10:44:25,090 p=3297 u=root |  skipping: [k8-master]
2020-08-05 10:44:25,098 p=3297 u=root |  skipping: [k8-node]
2020-08-05 10:44:25,102 p=3297 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] ***************************************
2020-08-05 10:44:25,118 p=3297 u=root |  skipping: [k8-master]
2020-08-05 10:44:25,124 p=3297 u=root |  skipping: [k8-node]
2020-08-05 10:44:25,130 p=3297 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] *********************************
2020-08-05 10:44:25,563 p=3297 u=root |  changed: [k8-node]
2020-08-05 10:44:25,568 p=3297 u=root |  changed: [k8-master]
2020-08-05 10:44:25,573 p=3297 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] ************************************
2020-08-05 10:44:25,589 p=3297 u=root |  skipping: [k8-master]
2020-08-05 10:44:25,598 p=3297 u=root |  skipping: [k8-node]
2020-08-05 10:44:25,603 p=3297 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] ***********************
2020-08-05 10:44:25,657 p=3297 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:44:25,667 p=3297 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:44:25,672 p=3297 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ***********************
2020-08-05 10:44:26,434 p=3297 u=root |  ok: [k8-master]
2020-08-05 10:44:26,435 p=3297 u=root |  ok: [k8-node]
2020-08-05 10:44:26,439 p=3297 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] **************************
2020-08-05 10:44:26,905 p=3297 u=root |  ok: [k8-node]
2020-08-05 10:44:26,905 p=3297 u=root |  ok: [k8-master]
2020-08-05 10:44:26,910 p=3297 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ****************
2020-08-05 10:44:26,959 p=3297 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 10:44:26,959 p=3297 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 10:44:26,960 p=3297 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 10:44:26,960 p=3297 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 10:44:26,963 p=3297 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 10:44:26,963 p=3297 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 10:44:26,963 p=3297 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 10:44:27,597 p=3297 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 10:44:28,111 p=3297 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 10:44:28,652 p=3297 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 10:44:29,186 p=3297 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 10:44:29,712 p=3297 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 10:44:30,238 p=3297 u=root |  ok: [k8-master] => (item=80)
2020-08-05 10:44:30,774 p=3297 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 10:44:30,782 p=3297 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ***************
2020-08-05 10:44:30,815 p=3297 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 10:44:30,815 p=3297 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 10:44:30,815 p=3297 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 10:44:30,820 p=3297 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 10:44:30,820 p=3297 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 10:44:30,820 p=3297 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 10:44:31,359 p=3297 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 10:44:31,896 p=3297 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 10:44:32,397 p=3297 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 10:44:32,948 p=3297 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 10:44:33,475 p=3297 u=root |  ok: [k8-node] => (item=80)
2020-08-05 10:44:33,997 p=3297 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 10:44:34,002 p=3297 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] ***************************
2020-08-05 10:44:34,378 p=3297 u=root |  changed: [k8-master]
2020-08-05 10:44:34,395 p=3297 u=root |  changed: [k8-node]
2020-08-05 10:44:34,400 p=3297 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ******************
2020-08-05 10:44:34,416 p=3297 u=root |  skipping: [k8-master]
2020-08-05 10:44:34,423 p=3297 u=root |  skipping: [k8-node]
2020-08-05 10:44:34,429 p=3297 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] **********
2020-08-05 10:44:34,899 p=3297 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:44:34,941 p=3297 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:44:35,232 p=3297 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:44:35,255 p=3297 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:44:35,261 p=3297 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ************
2020-08-05 10:44:35,609 p=3297 u=root |  changed: [k8-master]
2020-08-05 10:44:35,629 p=3297 u=root |  changed: [k8-node]
2020-08-05 10:44:35,634 p=3297 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ***********
2020-08-05 10:44:36,218 p=3297 u=root |  ok: [k8-master]
2020-08-05 10:44:36,226 p=3297 u=root |  ok: [k8-node]
2020-08-05 10:44:36,231 p=3297 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ****
2020-08-05 10:44:36,990 p=3297 u=root |  changed: [k8-master]
2020-08-05 10:44:36,994 p=3297 u=root |  changed: [k8-node]
2020-08-05 10:44:36,999 p=3297 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ********
2020-08-05 10:49:18,501 p=3297 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "file:///mnt/repodata/repomd.xml: [Errno 14] curl#37 - \"Couldn't open file /mnt/repodata/repomd.xml\"\nTrying other mirror.\nwarning: /var/cache/yum/x86_64/7Server/extras/packages/container-selinux-2.119.2-1.911c772.el7_8.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\nhttp://mirror.centos.org/centos/7/extras/x86_64/Packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: [Errno 12] Timeout on http://mirror.centos.org/centos/7/extras/x86_64/Packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: (28, 'Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds')\nTrying other mirror.\nhttp://mirror.centos.org/centos/7/extras/x86_64/Packages/docker-1.13.1-162.git64e9980.el7.centos.x86_64.rpm: [Errno 12] Timeout on http://mirror.centos.org/centos/7/extras/x86_64/Packages/docker-1.13.1-162.git64e9980.el7.centos.x86_64.rpm: (28, 'Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds')\nTrying other mirror.\n\n\nError downloading packages:\n  libyaml-0.1.4-11.el7_0.x86_64: [Errno 256] No more mirrors to try.\n  libnetfilter_queue-1.0.2-2.el7_2.x86_64: [Errno 256] No more mirrors to try.\n  PyYAML-3.10-11.el7.x86_64: [Errno 256] No more mirrors to try.\n  socat-1.7.3.2-2.el7.x86_64: [Errno 256] No more mirrors to try.\n\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal download size: 97 M\nDownloading packages:\nNo Presto metadata available for base\nNo Presto metadata available for updates\nPublic key for container-selinux-2.119.2-1.911c772.el7_8.noarch.rpm is not installed\nPublic key for conntrack-tools-1.4.4-7.el7.x86_64.rpm is not installed\nPublic key for selinux-policy-3.13.1-266.el7_8.1.noarch.rpm is not installed\n"]}
2020-08-05 10:51:20,359 p=3297 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "Repository extras is listed more than once in the configuration\nRepository updates is listed more than once in the configuration\nRepository base is listed more than once in the configuration\nfile:///mnt/repodata/repomd.xml: [Errno 14] curl#37 - \"Couldn't open file /mnt/repodata/repomd.xml\"\nTrying other mirror.\nwarning: /var/cache/yum/x86_64/7Server/extras/packages/container-selinux-2.119.2-1.911c772.el7_8.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\nhttp://mirror.centos.org/centos/7/extras/x86_64/Packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: [Errno 12] Timeout on http://mirror.centos.org/centos/7/extras/x86_64/Packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: (28, 'Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds')\nTrying other mirror.\nhttp://mirror.centos.org/centos/7/extras/x86_64/Packages/containers-common-0.1.40-11.el7_8.x86_64.rpm: [Errno 12] Timeout on http://mirror.centos.org/centos/7/extras/x86_64/Packages/containers-common-0.1.40-11.el7_8.x86_64.rpm: (28, 'Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds')\nTrying other mirror.\n\n\nError downloading packages:\n  libyaml-0.1.4-11.el7_0.x86_64: [Errno 256] No more mirrors to try.\n  libnetfilter_queue-1.0.2-2.el7_2.x86_64: [Errno 256] No more mirrors to try.\n  PyYAML-3.10-11.el7.x86_64: [Errno 256] No more mirrors to try.\n  socat-1.7.3.2-2.el7.x86_64: [Errno 256] No more mirrors to try.\n\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal download size: 97 M\nDownloading packages:\nNo Presto metadata available for base\nNo Presto metadata available for updates\nPublic key for container-selinux-2.119.2-1.911c772.el7_8.noarch.rpm is not installed\nPublic key for conntrack-tools-1.4.4-7.el7.x86_64.rpm is not installed\nPublic key for selinux-policy-3.13.1-266.el7_8.1.noarch.rpm is not installed\n"]}
2020-08-05 10:51:20,361 p=3297 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-05 10:51:20,361 p=3297 u=root |  PLAY RECAP ************************************************************************
2020-08-05 10:51:20,361 p=3297 u=root |  k8-master                  : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 10:51:20,361 p=3297 u=root |  k8-node                    : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 10:53:25,773 p=3749 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***
2020-08-05 10:53:25,782 p=3749 u=root |  TASK [Gathering Facts] ************************************************************
2020-08-05 10:53:26,969 p=3749 u=root |  ok: [k8-node]
2020-08-05 10:53:26,976 p=3749 u=root |  ok: [k8-master]
2020-08-05 10:53:26,981 p=3749 u=root |  TASK [Verifying if enough resources Present] **************************************
2020-08-05 10:53:26,996 p=3749 u=root |  skipping: [k8-master]
2020-08-05 10:53:27,004 p=3749 u=root |  skipping: [k8-node]
2020-08-05 10:53:27,009 p=3749 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] ***************************************
2020-08-05 10:53:27,027 p=3749 u=root |  skipping: [k8-master]
2020-08-05 10:53:27,034 p=3749 u=root |  skipping: [k8-node]
2020-08-05 10:53:27,039 p=3749 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] *********************************
2020-08-05 10:53:27,477 p=3749 u=root |  changed: [k8-node]
2020-08-05 10:53:27,483 p=3749 u=root |  changed: [k8-master]
2020-08-05 10:53:27,488 p=3749 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] ************************************
2020-08-05 10:53:27,512 p=3749 u=root |  skipping: [k8-master]
2020-08-05 10:53:27,514 p=3749 u=root |  skipping: [k8-node]
2020-08-05 10:53:27,520 p=3749 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] ***********************
2020-08-05 10:53:27,576 p=3749 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:53:27,587 p=3749 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:53:27,592 p=3749 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] ***********************
2020-08-05 10:53:28,377 p=3749 u=root |  ok: [k8-node]
2020-08-05 10:53:28,390 p=3749 u=root |  ok: [k8-master]
2020-08-05 10:53:28,395 p=3749 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] **************************
2020-08-05 10:53:28,862 p=3749 u=root |  ok: [k8-master]
2020-08-05 10:53:28,866 p=3749 u=root |  ok: [k8-node]
2020-08-05 10:53:28,871 p=3749 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ****************
2020-08-05 10:53:28,921 p=3749 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 10:53:28,921 p=3749 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 10:53:28,922 p=3749 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 10:53:28,924 p=3749 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 10:53:28,924 p=3749 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 10:53:28,925 p=3749 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 10:53:28,925 p=3749 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 10:53:29,568 p=3749 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 10:53:30,096 p=3749 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 10:53:30,635 p=3749 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 10:53:31,204 p=3749 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 10:53:31,738 p=3749 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 10:53:32,303 p=3749 u=root |  ok: [k8-master] => (item=80)
2020-08-05 10:53:32,832 p=3749 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 10:53:32,838 p=3749 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] ***************
2020-08-05 10:53:32,876 p=3749 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 10:53:32,877 p=3749 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 10:53:32,877 p=3749 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 10:53:32,877 p=3749 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 10:53:32,878 p=3749 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 10:53:32,878 p=3749 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 10:53:33,438 p=3749 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 10:53:34,019 p=3749 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 10:53:34,632 p=3749 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 10:53:35,132 p=3749 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 10:53:35,702 p=3749 u=root |  ok: [k8-node] => (item=80)
2020-08-05 10:53:36,266 p=3749 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 10:53:36,272 p=3749 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] ***************************
2020-08-05 10:53:36,633 p=3749 u=root |  changed: [k8-master]
2020-08-05 10:53:36,646 p=3749 u=root |  changed: [k8-node]
2020-08-05 10:53:36,652 p=3749 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ******************
2020-08-05 10:53:36,667 p=3749 u=root |  skipping: [k8-master]
2020-08-05 10:53:36,677 p=3749 u=root |  skipping: [k8-node]
2020-08-05 10:53:36,682 p=3749 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] **********
2020-08-05 10:53:37,167 p=3749 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:53:37,210 p=3749 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:53:37,513 p=3749 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:53:37,525 p=3749 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:53:37,530 p=3749 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] ************
2020-08-05 10:53:37,891 p=3749 u=root |  changed: [k8-master]
2020-08-05 10:53:37,901 p=3749 u=root |  changed: [k8-node]
2020-08-05 10:53:37,906 p=3749 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] ***********
2020-08-05 10:53:38,526 p=3749 u=root |  ok: [k8-master]
2020-08-05 10:53:38,550 p=3749 u=root |  ok: [k8-node]
2020-08-05 10:53:38,556 p=3749 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ****
2020-08-05 10:53:39,161 p=3749 u=root |  ok: [k8-master]
2020-08-05 10:53:39,178 p=3749 u=root |  ok: [k8-node]
2020-08-05 10:53:39,183 p=3749 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] ********
2020-08-05 10:54:46,150 p=3749 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "warning: /var/cache/yum/x86_64/7Server/extras/packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n\n\nGPG key retrieval failed: [Errno 14] curl#37 - \"Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\"\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal size: 97 M\nTotal download size: 521 k\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                              4.5 MB/s | 521 kB  00:00     \nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n"]}
2020-08-05 10:54:46,300 p=3749 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "Repository extras is listed more than once in the configuration\nRepository updates is listed more than once in the configuration\nRepository base is listed more than once in the configuration\nwarning: /var/cache/yum/x86_64/7Server/extras/packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n\n\nGPG key retrieval failed: [Errno 14] curl#37 - \"Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\"\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal size: 97 M\nTotal download size: 521 k\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                               17 MB/s | 521 kB  00:00     \nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n"]}
2020-08-05 10:54:46,301 p=3749 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-05 10:54:46,302 p=3749 u=root |  PLAY RECAP ************************************************************************
2020-08-05 10:54:46,302 p=3749 u=root |  k8-master                  : ok=11   changed=3    unreachable=0    failed=1   
2020-08-05 10:54:46,302 p=3749 u=root |  k8-node                    : ok=11   changed=3    unreachable=0    failed=1   
2020-08-05 10:59:08,990 p=4118 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***********************************
2020-08-05 10:59:08,998 p=4118 u=root |  TASK [Gathering Facts] **************************************************************************************************************
2020-08-05 10:59:09,983 p=4118 u=root |  ok: [k8-node]
2020-08-05 10:59:09,997 p=4118 u=root |  ok: [k8-master]
2020-08-05 10:59:10,001 p=4118 u=root |  TASK [Verifying if enough resources Present] ****************************************************************************************
2020-08-05 10:59:10,016 p=4118 u=root |  skipping: [k8-master]
2020-08-05 10:59:10,025 p=4118 u=root |  skipping: [k8-node]
2020-08-05 10:59:10,030 p=4118 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-08-05 10:59:10,046 p=4118 u=root |  skipping: [k8-master]
2020-08-05 10:59:10,054 p=4118 u=root |  skipping: [k8-node]
2020-08-05 10:59:10,060 p=4118 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-08-05 10:59:10,513 p=4118 u=root |  changed: [k8-node]
2020-08-05 10:59:10,514 p=4118 u=root |  changed: [k8-master]
2020-08-05 10:59:10,518 p=4118 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-08-05 10:59:10,533 p=4118 u=root |  skipping: [k8-master]
2020-08-05 10:59:10,541 p=4118 u=root |  skipping: [k8-node]
2020-08-05 10:59:10,547 p=4118 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] *************************************************************************
2020-08-05 10:59:10,597 p=4118 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:59:10,610 p=4118 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 10:59:10,615 p=4118 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-08-05 10:59:11,384 p=4118 u=root |  ok: [k8-node]
2020-08-05 10:59:11,386 p=4118 u=root |  ok: [k8-master]
2020-08-05 10:59:11,391 p=4118 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-08-05 10:59:11,855 p=4118 u=root |  ok: [k8-master]
2020-08-05 10:59:11,860 p=4118 u=root |  ok: [k8-node]
2020-08-05 10:59:11,865 p=4118 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-08-05 10:59:11,915 p=4118 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 10:59:11,916 p=4118 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 10:59:11,916 p=4118 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 10:59:11,916 p=4118 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 10:59:11,918 p=4118 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 10:59:11,918 p=4118 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 10:59:11,919 p=4118 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 10:59:12,575 p=4118 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 10:59:13,099 p=4118 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 10:59:13,631 p=4118 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 10:59:14,161 p=4118 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 10:59:14,707 p=4118 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 10:59:15,244 p=4118 u=root |  ok: [k8-master] => (item=80)
2020-08-05 10:59:15,773 p=4118 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 10:59:15,779 p=4118 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] *****************************************************************
2020-08-05 10:59:15,813 p=4118 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 10:59:15,814 p=4118 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 10:59:15,814 p=4118 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 10:59:15,816 p=4118 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 10:59:15,816 p=4118 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 10:59:15,817 p=4118 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 10:59:16,344 p=4118 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 10:59:16,890 p=4118 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 10:59:17,409 p=4118 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 10:59:18,012 p=4118 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 10:59:18,552 p=4118 u=root |  ok: [k8-node] => (item=80)
2020-08-05 10:59:19,045 p=4118 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 10:59:19,049 p=4118 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] *****************************************************************************
2020-08-05 10:59:19,407 p=4118 u=root |  changed: [k8-master]
2020-08-05 10:59:19,423 p=4118 u=root |  changed: [k8-node]
2020-08-05 10:59:19,429 p=4118 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ********************************************************************
2020-08-05 10:59:19,444 p=4118 u=root |  skipping: [k8-master]
2020-08-05 10:59:19,454 p=4118 u=root |  skipping: [k8-node]
2020-08-05 10:59:19,459 p=4118 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ************************************************************
2020-08-05 10:59:19,965 p=4118 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:59:19,967 p=4118 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 10:59:20,287 p=4118 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:59:20,287 p=4118 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 10:59:20,293 p=4118 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] **************************************************************
2020-08-05 10:59:20,666 p=4118 u=root |  changed: [k8-master]
2020-08-05 10:59:20,680 p=4118 u=root |  changed: [k8-node]
2020-08-05 10:59:20,685 p=4118 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] *************************************************************
2020-08-05 10:59:21,263 p=4118 u=root |  ok: [k8-master]
2020-08-05 10:59:21,278 p=4118 u=root |  ok: [k8-node]
2020-08-05 10:59:21,283 p=4118 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ******************************************************
2020-08-05 10:59:22,025 p=4118 u=root |  changed: [k8-node]
2020-08-05 10:59:22,041 p=4118 u=root |  changed: [k8-master]
2020-08-05 10:59:22,045 p=4118 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] **********************************************************
2020-08-05 11:00:29,720 p=4118 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "warning: /var/cache/yum/x86_64/7Server/extras/packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n\n\nGPG key retrieval failed: [Errno 14] curl#37 - \"Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\"\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal size: 97 M\nTotal download size: 521 k\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                              123 MB/s | 521 kB  00:00     \nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n"]}
2020-08-05 11:00:29,743 p=4118 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "warning: /var/cache/yum/x86_64/7Server/extras/packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n\n\nGPG key retrieval failed: [Errno 14] curl#37 - \"Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\"\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal size: 97 M\nTotal download size: 521 k\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                              101 MB/s | 521 kB  00:00     \nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n"]}
2020-08-05 11:00:29,745 p=4118 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-05 11:00:29,745 p=4118 u=root |  PLAY RECAP **************************************************************************************************************************
2020-08-05 11:00:29,745 p=4118 u=root |  k8-master                  : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 11:00:29,746 p=4118 u=root |  k8-node                    : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 11:02:07,723 p=4477 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***********************************
2020-08-05 11:02:07,731 p=4477 u=root |  TASK [Gathering Facts] **************************************************************************************************************
2020-08-05 11:02:08,880 p=4477 u=root |  ok: [k8-master]
2020-08-05 11:02:08,883 p=4477 u=root |  ok: [k8-node]
2020-08-05 11:02:08,887 p=4477 u=root |  TASK [Verifying if enough resources Present] ****************************************************************************************
2020-08-05 11:02:08,902 p=4477 u=root |  skipping: [k8-master]
2020-08-05 11:02:08,911 p=4477 u=root |  skipping: [k8-node]
2020-08-05 11:02:08,915 p=4477 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-08-05 11:02:08,930 p=4477 u=root |  skipping: [k8-master]
2020-08-05 11:02:08,939 p=4477 u=root |  skipping: [k8-node]
2020-08-05 11:02:08,944 p=4477 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-08-05 11:02:09,399 p=4477 u=root |  changed: [k8-node]
2020-08-05 11:02:09,403 p=4477 u=root |  changed: [k8-master]
2020-08-05 11:02:09,409 p=4477 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-08-05 11:02:09,424 p=4477 u=root |  skipping: [k8-master]
2020-08-05 11:02:09,431 p=4477 u=root |  skipping: [k8-node]
2020-08-05 11:02:09,437 p=4477 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] *************************************************************************
2020-08-05 11:02:09,489 p=4477 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 11:02:09,500 p=4477 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 11:02:09,506 p=4477 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-08-05 11:02:10,263 p=4477 u=root |  ok: [k8-node]
2020-08-05 11:02:10,263 p=4477 u=root |  ok: [k8-master]
2020-08-05 11:02:10,268 p=4477 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-08-05 11:02:10,741 p=4477 u=root |  ok: [k8-node]
2020-08-05 11:02:10,744 p=4477 u=root |  ok: [k8-master]
2020-08-05 11:02:10,749 p=4477 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-08-05 11:02:10,798 p=4477 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 11:02:10,799 p=4477 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 11:02:10,799 p=4477 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 11:02:10,799 p=4477 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 11:02:10,801 p=4477 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 11:02:10,801 p=4477 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 11:02:10,802 p=4477 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 11:02:11,445 p=4477 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 11:02:11,991 p=4477 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 11:02:12,528 p=4477 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 11:02:13,063 p=4477 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 11:02:13,597 p=4477 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 11:02:14,144 p=4477 u=root |  ok: [k8-master] => (item=80)
2020-08-05 11:02:14,689 p=4477 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 11:02:14,696 p=4477 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] *****************************************************************
2020-08-05 11:02:14,731 p=4477 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 11:02:14,732 p=4477 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 11:02:14,732 p=4477 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 11:02:14,732 p=4477 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 11:02:14,732 p=4477 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 11:02:14,733 p=4477 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 11:02:15,280 p=4477 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 11:02:15,826 p=4477 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 11:02:16,361 p=4477 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 11:02:16,918 p=4477 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 11:02:17,459 p=4477 u=root |  ok: [k8-node] => (item=80)
2020-08-05 11:02:18,030 p=4477 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 11:02:18,035 p=4477 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] *****************************************************************************
2020-08-05 11:02:18,396 p=4477 u=root |  changed: [k8-master]
2020-08-05 11:02:18,406 p=4477 u=root |  changed: [k8-node]
2020-08-05 11:02:18,411 p=4477 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ********************************************************************
2020-08-05 11:02:18,425 p=4477 u=root |  skipping: [k8-master]
2020-08-05 11:02:18,435 p=4477 u=root |  skipping: [k8-node]
2020-08-05 11:02:18,440 p=4477 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ************************************************************
2020-08-05 11:02:18,919 p=4477 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 11:02:18,967 p=4477 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 11:02:19,261 p=4477 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 11:02:19,281 p=4477 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 11:02:19,288 p=4477 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] **************************************************************
2020-08-05 11:02:19,647 p=4477 u=root |  changed: [k8-master]
2020-08-05 11:02:19,655 p=4477 u=root |  changed: [k8-node]
2020-08-05 11:02:19,660 p=4477 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] *************************************************************
2020-08-05 11:02:20,249 p=4477 u=root |  ok: [k8-master]
2020-08-05 11:02:20,269 p=4477 u=root |  ok: [k8-node]
2020-08-05 11:02:20,274 p=4477 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ******************************************************
2020-08-05 11:02:21,059 p=4477 u=root |  changed: [k8-master]
2020-08-05 11:02:21,063 p=4477 u=root |  changed: [k8-node]
2020-08-05 11:02:21,068 p=4477 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] **********************************************************
2020-08-05 11:03:28,421 p=4477 u=root |  fatal: [k8-master]: FAILED! => {"changed": false, "failed": true, "msg": "warning: /var/cache/yum/x86_64/7Server/extras/packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n\n\nGPG key retrieval failed: [Errno 14] curl#37 - \"Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\"\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal size: 97 M\nTotal download size: 521 k\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                              138 MB/s | 521 kB  00:00     \nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n"]}
2020-08-05 11:03:29,902 p=4477 u=root |  fatal: [k8-node]: FAILED! => {"changed": false, "failed": true, "msg": "warning: /var/cache/yum/x86_64/7Server/extras/packages/atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID f4a80eb5: NOKEY\n\n\nGPG key retrieval failed: [Errno 14] curl#37 - \"Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\"\n", "rc": 1, "results": ["Loaded plugins: langpacks, product-id, search-disabled-repos, subscription-\n              : manager\nThis system is not registered with an entitlement server. You can use subscription-manager to register.\nResolving Dependencies\n--> Running transaction check\n---> Package docker.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: docker-common = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: docker-client = 2:1.13.1-162.git64e9980.el7.centos for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: subscription-manager-rhsm-certificates for package: 2:docker-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubeadm.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: kubernetes-cni >= 0.8.6 for package: kubeadm-1.18.6-0.x86_64\n--> Processing Dependency: cri-tools >= 1.13.0 for package: kubeadm-1.18.6-0.x86_64\n---> Package kubectl.x86_64 0:1.18.6-0 will be installed\n---> Package kubelet.x86_64 0:1.18.6-0 will be installed\n--> Processing Dependency: socat for package: kubelet-1.18.6-0.x86_64\n--> Processing Dependency: conntrack for package: kubelet-1.18.6-0.x86_64\n--> Running transaction check\n---> Package conntrack-tools.x86_64 0:1.4.4-7.el7 will be installed\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.1)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1(LIBNETFILTER_CTTIMEOUT_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0(LIBNETFILTER_CTHELPER_1.0)(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_queue.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cttimeout.so.1()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n--> Processing Dependency: libnetfilter_cthelper.so.0()(64bit) for package: conntrack-tools-1.4.4-7.el7.x86_64\n---> Package cri-tools.x86_64 0:1.13.0-0 will be installed\n---> Package docker-client.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n---> Package docker-common.x86_64 2:1.13.1-162.git64e9980.el7.centos will be installed\n--> Processing Dependency: skopeo-containers >= 1:0.1.26-2 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-umount >= 2:2.3.3-3 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-systemd-hook >= 1:0.1.4-9 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: oci-register-machine >= 1:0-5.13 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-storage-setup >= 0.9.0-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: container-selinux >= 2:2.51-1 for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n--> Processing Dependency: atomic-registries for package: 2:docker-common-1.13.1-162.git64e9980.el7.centos.x86_64\n---> Package kubernetes-cni.x86_64 0:0.8.6-0 will be installed\n---> Package python-rhsm-certificates.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n--> Processing Dependency: python-rhsm-certificates = 1.19.10-1.el7_4 for package: python-rhsm-1.19.10-1.el7_4.x86_64\n---> Package socat.x86_64 0:1.7.3.2-2.el7 will be installed\n---> Package subscription-manager-rhsm-certificates.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package atomic-registries.x86_64 1:1.22.1-33.gitb507039.el7_8 will be installed\n--> Processing Dependency: python-yaml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n--> Processing Dependency: python-pytoml for package: 1:atomic-registries-1.22.1-33.gitb507039.el7_8.x86_64\n---> Package container-selinux.noarch 2:2.119.2-1.911c772.el7_8 will be installed\n--> Processing Dependency: selinux-policy-targeted >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy-base >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n--> Processing Dependency: selinux-policy >= 3.13.1-216.el7 for package: 2:container-selinux-2.119.2-1.911c772.el7_8.noarch\n---> Package container-storage-setup.noarch 0:0.11.0-2.git5eaf76c.el7 will be installed\n---> Package containers-common.x86_64 1:0.1.40-11.el7_8 will be installed\n--> Processing Dependency: slirp4netns for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n--> Processing Dependency: fuse-overlayfs for package: 1:containers-common-0.1.40-11.el7_8.x86_64\n---> Package libnetfilter_cthelper.x86_64 0:1.0.0-11.el7 will be installed\n---> Package libnetfilter_cttimeout.x86_64 0:1.0.0-7.el7 will be installed\n---> Package libnetfilter_queue.x86_64 0:1.0.2-2.el7_2 will be installed\n---> Package oci-register-machine.x86_64 1:0-6.git2b44233.el7 will be installed\n---> Package oci-systemd-hook.x86_64 1:0.2.0-1.git05e6923.el7_6 will be installed\n---> Package oci-umount.x86_64 2:2.5-3.el7 will be installed\n---> Package python-rhsm.x86_64 0:1.19.10-1.el7_4 will be obsoleted\n---> Package subscription-manager-rhsm.x86_64 0:1.24.26-3.el7.centos will be obsoleting\n--> Running transaction check\n---> Package PyYAML.x86_64 0:3.10-11.el7 will be installed\n--> Processing Dependency: libyaml-0.so.2()(64bit) for package: PyYAML-3.10-11.el7.x86_64\n---> Package fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 will be installed\n--> Processing Dependency: libfuse3.so.3(FUSE_3.2)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3(FUSE_3.0)(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n--> Processing Dependency: libfuse3.so.3()(64bit) for package: fuse-overlayfs-0.7.2-6.el7_8.x86_64\n---> Package python-pytoml.noarch 0:0.1.14-1.git7dea353.el7 will be installed\n---> Package selinux-policy.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy.noarch 0:3.13.1-266.el7_8.1 will be an update\n--> Processing Dependency: policycoreutils >= 2.5-24 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n--> Processing Dependency: libsemanage >= 2.5-13 for package: selinux-policy-3.13.1-266.el7_8.1.noarch\n---> Package selinux-policy-targeted.noarch 0:3.13.1-166.el7_4.7 will be updated\n---> Package selinux-policy-targeted.noarch 0:3.13.1-266.el7_8.1 will be an update\n---> Package slirp4netns.x86_64 0:0.4.3-4.el7_8 will be installed\n--> Running transaction check\n---> Package fuse3-libs.x86_64 0:3.6.1-4.el7 will be installed\n---> Package libsemanage.x86_64 0:2.5-8.el7 will be updated\n--> Processing Dependency: libsemanage = 2.5-8.el7 for package: libsemanage-python-2.5-8.el7.x86_64\n---> Package libsemanage.x86_64 0:2.5-14.el7 will be an update\n--> Processing Dependency: libsepol >= 2.5-10 for package: libsemanage-2.5-14.el7.x86_64\n--> Processing Dependency: libselinux >= 2.5-14 for package: libsemanage-2.5-14.el7.x86_64\n---> Package libyaml.x86_64 0:0.1.4-11.el7_0 will be installed\n---> Package policycoreutils.x86_64 0:2.5-17.1.el7 will be updated\n--> Processing Dependency: policycoreutils = 2.5-17.1.el7 for package: policycoreutils-python-2.5-17.1.el7.x86_64\n---> Package policycoreutils.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: libselinux-utils >= 2.5-14 for package: policycoreutils-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux.x86_64 0:2.5-11.el7 will be updated\n--> Processing Dependency: libselinux(x86-64) = 2.5-11.el7 for package: libselinux-python-2.5-11.el7.x86_64\n---> Package libselinux.x86_64 0:2.5-15.el7 will be an update\n---> Package libselinux-utils.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-utils.x86_64 0:2.5-15.el7 will be an update\n---> Package libsemanage-python.x86_64 0:2.5-8.el7 will be updated\n---> Package libsemanage-python.x86_64 0:2.5-14.el7 will be an update\n---> Package libsepol.x86_64 0:2.5-6.el7 will be updated\n---> Package libsepol.x86_64 0:2.5-10.el7 will be an update\n---> Package policycoreutils-python.x86_64 0:2.5-17.1.el7 will be updated\n---> Package policycoreutils-python.x86_64 0:2.5-34.el7 will be an update\n--> Processing Dependency: setools-libs >= 3.3.8-4 for package: policycoreutils-python-2.5-34.el7.x86_64\n--> Running transaction check\n---> Package libselinux-python.x86_64 0:2.5-11.el7 will be updated\n---> Package libselinux-python.x86_64 0:2.5-15.el7 will be an update\n---> Package setools-libs.x86_64 0:3.3.8-1.1.el7 will be updated\n---> Package setools-libs.x86_64 0:3.3.8-4.el7 will be an update\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                 Arch   Version                      Repository    Size\n================================================================================\nInstalling:\n docker                  x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        18 M\n kubeadm                 x86_64 1.18.6-0                     kubernetes   8.8 M\n kubectl                 x86_64 1.18.6-0                     kubernetes   9.5 M\n kubelet                 x86_64 1.18.6-0                     kubernetes    21 M\n subscription-manager-rhsm\n                         x86_64 1.24.26-3.el7.centos         updates      327 k\n     replacing  python-rhsm.x86_64 1.19.10-1.el7_4\n subscription-manager-rhsm-certificates\n                         x86_64 1.24.26-3.el7.centos         updates      232 k\n     replacing  python-rhsm-certificates.x86_64 1.19.10-1.el7_4\nInstalling for dependencies:\n PyYAML                  x86_64 3.10-11.el7                  InstallMedia 153 k\n atomic-registries       x86_64 1:1.22.1-33.gitb507039.el7_8 extras        36 k\n conntrack-tools         x86_64 1.4.4-7.el7                  base         187 k\n container-selinux       noarch 2:2.119.2-1.911c772.el7_8    extras        40 k\n container-storage-setup noarch 0.11.0-2.git5eaf76c.el7      extras        35 k\n containers-common       x86_64 1:0.1.40-11.el7_8            extras        43 k\n cri-tools               x86_64 1.13.0-0                     kubernetes   5.1 M\n docker-client           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras       3.9 M\n docker-common           x86_64 2:1.13.1-162.git64e9980.el7.centos\n                                                             extras        99 k\n fuse-overlayfs          x86_64 0.7.2-6.el7_8                extras        54 k\n fuse3-libs              x86_64 3.6.1-4.el7                  extras        82 k\n kubernetes-cni          x86_64 0.8.6-0                      kubernetes    18 M\n libnetfilter_cthelper   x86_64 1.0.0-11.el7                 base          18 k\n libnetfilter_cttimeout  x86_64 1.0.0-7.el7                  base          18 k\n libnetfilter_queue      x86_64 1.0.2-2.el7_2                InstallMedia  23 k\n libyaml                 x86_64 0.1.4-11.el7_0               InstallMedia  55 k\n oci-register-machine    x86_64 1:0-6.git2b44233.el7         extras       1.1 M\n oci-systemd-hook        x86_64 1:0.2.0-1.git05e6923.el7_6   extras        34 k\n oci-umount              x86_64 2:2.5-3.el7                  extras        33 k\n python-pytoml           noarch 0.1.14-1.git7dea353.el7      extras        18 k\n slirp4netns             x86_64 0.4.3-4.el7_8                extras        81 k\n socat                   x86_64 1.7.3.2-2.el7                InstallMedia 290 k\nUpdating for dependencies:\n libselinux              x86_64 2.5-15.el7                   base         162 k\n libselinux-python       x86_64 2.5-15.el7                   base         236 k\n libselinux-utils        x86_64 2.5-15.el7                   base         151 k\n libsemanage             x86_64 2.5-14.el7                   base         151 k\n libsemanage-python      x86_64 2.5-14.el7                   base         113 k\n libsepol                x86_64 2.5-10.el7                   base         297 k\n policycoreutils         x86_64 2.5-34.el7                   base         917 k\n policycoreutils-python  x86_64 2.5-34.el7                   base         457 k\n selinux-policy          noarch 3.13.1-266.el7_8.1           updates      497 k\n selinux-policy-targeted noarch 3.13.1-266.el7_8.1           updates      7.0 M\n setools-libs            x86_64 3.3.8-4.el7                  base         620 k\n\nTransaction Summary\n================================================================================\nInstall  6 Packages (+22 Dependent packages)\nUpgrade             ( 11 Dependent packages)\n\nTotal size: 97 M\nTotal download size: 521 k\nDownloading packages:\n--------------------------------------------------------------------------------\nTotal                                              141 MB/s | 521 kB  00:00     \nRetrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n"]}
2020-08-05 11:03:29,904 p=4477 u=root |  	to retry, use: --limit @/opt/python/ansible/kubernetesCluster/kubernetes.retry

2020-08-05 11:03:29,904 p=4477 u=root |  PLAY RECAP **************************************************************************************************************************
2020-08-05 11:03:29,904 p=4477 u=root |  k8-master                  : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 11:03:29,904 p=4477 u=root |  k8-node                    : ok=11   changed=4    unreachable=0    failed=1   
2020-08-05 11:04:43,494 p=4903 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***********************************
2020-08-05 11:04:43,503 p=4903 u=root |  TASK [Gathering Facts] **************************************************************************************************************
2020-08-05 11:04:44,616 p=4903 u=root |  ok: [k8-node]
2020-08-05 11:04:44,701 p=4903 u=root |  ok: [k8-master]
2020-08-05 11:04:44,706 p=4903 u=root |  TASK [Verifying if enough resources Present] ****************************************************************************************
2020-08-05 11:04:44,723 p=4903 u=root |  skipping: [k8-master]
2020-08-05 11:04:44,731 p=4903 u=root |  skipping: [k8-node]
2020-08-05 11:04:44,735 p=4903 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-08-05 11:04:44,753 p=4903 u=root |  skipping: [k8-master]
2020-08-05 11:04:44,761 p=4903 u=root |  skipping: [k8-node]
2020-08-05 11:04:44,767 p=4903 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-08-05 11:04:45,199 p=4903 u=root |  changed: [k8-master]
2020-08-05 11:04:45,210 p=4903 u=root |  changed: [k8-node]
2020-08-05 11:04:45,215 p=4903 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-08-05 11:04:45,236 p=4903 u=root |  skipping: [k8-master]
2020-08-05 11:04:45,241 p=4903 u=root |  skipping: [k8-node]
2020-08-05 11:04:45,246 p=4903 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] *************************************************************************
2020-08-05 11:04:45,299 p=4903 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 11:04:45,310 p=4903 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 11:04:45,315 p=4903 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-08-05 11:04:46,095 p=4903 u=root |  ok: [k8-master]
2020-08-05 11:04:46,095 p=4903 u=root |  ok: [k8-node]
2020-08-05 11:04:46,100 p=4903 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-08-05 11:04:46,566 p=4903 u=root |  ok: [k8-master]
2020-08-05 11:04:46,566 p=4903 u=root |  ok: [k8-node]
2020-08-05 11:04:46,571 p=4903 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-08-05 11:04:46,621 p=4903 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 11:04:46,622 p=4903 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 11:04:46,622 p=4903 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 11:04:46,622 p=4903 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 11:04:46,625 p=4903 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 11:04:46,625 p=4903 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 11:04:46,625 p=4903 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 11:04:47,263 p=4903 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 11:04:47,780 p=4903 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 11:04:48,323 p=4903 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 11:04:48,855 p=4903 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 11:04:49,378 p=4903 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 11:04:49,904 p=4903 u=root |  ok: [k8-master] => (item=80)
2020-08-05 11:04:50,452 p=4903 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 11:04:50,457 p=4903 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] *****************************************************************
2020-08-05 11:04:50,492 p=4903 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 11:04:50,493 p=4903 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 11:04:50,493 p=4903 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 11:04:50,493 p=4903 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 11:04:50,494 p=4903 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 11:04:50,494 p=4903 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 11:04:51,026 p=4903 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 11:04:51,550 p=4903 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 11:04:52,077 p=4903 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 11:04:52,688 p=4903 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 11:04:53,232 p=4903 u=root |  ok: [k8-node] => (item=80)
2020-08-05 11:04:53,722 p=4903 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 11:04:53,727 p=4903 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] *****************************************************************************
2020-08-05 11:04:54,083 p=4903 u=root |  changed: [k8-master]
2020-08-05 11:04:54,094 p=4903 u=root |  changed: [k8-node]
2020-08-05 11:04:54,099 p=4903 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ********************************************************************
2020-08-05 11:04:54,114 p=4903 u=root |  skipping: [k8-master]
2020-08-05 11:04:54,123 p=4903 u=root |  skipping: [k8-node]
2020-08-05 11:04:54,128 p=4903 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ************************************************************
2020-08-05 11:04:54,620 p=4903 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 11:04:54,658 p=4903 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 11:04:54,962 p=4903 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 11:04:54,972 p=4903 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 11:04:54,977 p=4903 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] **************************************************************
2020-08-05 11:04:55,336 p=4903 u=root |  changed: [k8-master]
2020-08-05 11:04:55,343 p=4903 u=root |  changed: [k8-node]
2020-08-05 11:04:55,347 p=4903 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] *************************************************************
2020-08-05 11:04:55,931 p=4903 u=root |  ok: [k8-master]
2020-08-05 11:04:55,942 p=4903 u=root |  ok: [k8-node]
2020-08-05 11:04:55,947 p=4903 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ******************************************************
2020-08-05 11:04:56,706 p=4903 u=root |  changed: [k8-node]
2020-08-05 11:04:56,710 p=4903 u=root |  changed: [k8-master]
2020-08-05 11:04:56,716 p=4903 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] **********************************************************
2020-08-05 11:06:03,010 p=4903 u=root |   [ERROR]: User interrupted execution

2020-08-05 11:06:08,814 p=5230 u=root |  PLAY [---------------------- | KUBERNETES CLUSTER DEPLOYMENT | ---------------------------------] ***********************************
2020-08-05 11:06:08,823 p=5230 u=root |  TASK [Gathering Facts] **************************************************************************************************************
2020-08-05 11:06:09,684 p=5230 u=root |  ok: [k8-node]
2020-08-05 11:06:09,696 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:06:09,701 p=5230 u=root |  TASK [Verifying if enough resources Present] ****************************************************************************************
2020-08-05 11:06:09,718 p=5230 u=root |  skipping: [k8-master]
2020-08-05 11:06:09,727 p=5230 u=root |  skipping: [k8-node]
2020-08-05 11:06:09,731 p=5230 u=root |  TASK [Pre-Requisite-1 |Switching off swap|] *****************************************************************************************
2020-08-05 11:06:09,751 p=5230 u=root |  skipping: [k8-master]
2020-08-05 11:06:09,760 p=5230 u=root |  skipping: [k8-node]
2020-08-05 11:06:09,765 p=5230 u=root |  TASK [Pre-Requisite-2 |Gathering selinux status|] ***********************************************************************************
2020-08-05 11:06:10,298 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:06:10,300 p=5230 u=root |  changed: [k8-node]
2020-08-05 11:06:10,305 p=5230 u=root |  TASK [Pre-Requisite-3 |Switching off selinux|] **************************************************************************************
2020-08-05 11:06:10,321 p=5230 u=root |  skipping: [k8-master]
2020-08-05 11:06:10,330 p=5230 u=root |  skipping: [k8-node]
2020-08-05 11:06:10,336 p=5230 u=root |  TASK [deploy_kubernetes : 0. Starting with role deployment] *************************************************************************
2020-08-05 11:06:10,390 p=5230 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 11:06:10,405 p=5230 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment started ... "
}
2020-08-05 11:06:10,411 p=5230 u=root |  TASK [deploy_kubernetes : 1. Permanently disabling Selinux] *************************************************************************
2020-08-05 11:06:11,234 p=5230 u=root |  ok: [k8-node]
2020-08-05 11:06:11,236 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:06:11,241 p=5230 u=root |  TASK [deploy_kubernetes : 2. Permanently disabling swap] ****************************************************************************
2020-08-05 11:06:11,744 p=5230 u=root |  ok: [k8-node]
2020-08-05 11:06:11,748 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:06:11,753 p=5230 u=root |  TASK [deploy_kubernetes : 3. Setting up firewall rules for master] ******************************************************************
2020-08-05 11:06:11,808 p=5230 u=root |  skipping: [k8-node] => (item=6443) 
2020-08-05 11:06:11,808 p=5230 u=root |  skipping: [k8-node] => (item=2379-2380) 
2020-08-05 11:06:11,809 p=5230 u=root |  skipping: [k8-node] => (item=10250) 
2020-08-05 11:06:11,809 p=5230 u=root |  skipping: [k8-node] => (item=10251) 
2020-08-05 11:06:11,811 p=5230 u=root |  skipping: [k8-node] => (item=10252) 
2020-08-05 11:06:11,811 p=5230 u=root |  skipping: [k8-node] => (item=80) 
2020-08-05 11:06:11,811 p=5230 u=root |  skipping: [k8-node] => (item=8080) 
2020-08-05 11:06:12,447 p=5230 u=root |  ok: [k8-master] => (item=6443)
2020-08-05 11:06:13,026 p=5230 u=root |  ok: [k8-master] => (item=2379-2380)
2020-08-05 11:06:13,576 p=5230 u=root |  ok: [k8-master] => (item=10250)
2020-08-05 11:06:14,134 p=5230 u=root |  ok: [k8-master] => (item=10251)
2020-08-05 11:06:14,680 p=5230 u=root |  ok: [k8-master] => (item=10252)
2020-08-05 11:06:15,219 p=5230 u=root |  ok: [k8-master] => (item=80)
2020-08-05 11:06:15,756 p=5230 u=root |  ok: [k8-master] => (item=8080)
2020-08-05 11:06:15,763 p=5230 u=root |  TASK [deploy_kubernetes : 4. Setting up firewall rules for workers] *****************************************************************
2020-08-05 11:06:15,796 p=5230 u=root |  skipping: [k8-master] => (item=10250) 
2020-08-05 11:06:15,797 p=5230 u=root |  skipping: [k8-master] => (item=10255) 
2020-08-05 11:06:15,797 p=5230 u=root |  skipping: [k8-master] => (item=30000-32767) 
2020-08-05 11:06:15,800 p=5230 u=root |  skipping: [k8-master] => (item=6783) 
2020-08-05 11:06:15,801 p=5230 u=root |  skipping: [k8-master] => (item=80) 
2020-08-05 11:06:15,801 p=5230 u=root |  skipping: [k8-master] => (item=8080) 
2020-08-05 11:06:16,360 p=5230 u=root |  ok: [k8-node] => (item=10250)
2020-08-05 11:06:16,912 p=5230 u=root |  ok: [k8-node] => (item=10255)
2020-08-05 11:06:17,452 p=5230 u=root |  ok: [k8-node] => (item=30000-32767)
2020-08-05 11:06:18,021 p=5230 u=root |  ok: [k8-node] => (item=6783)
2020-08-05 11:06:18,561 p=5230 u=root |  ok: [k8-node] => (item=80)
2020-08-05 11:06:19,110 p=5230 u=root |  ok: [k8-node] => (item=8080)
2020-08-05 11:06:19,115 p=5230 u=root |  TASK [deploy_kubernetes : 5. netfilter module checking] *****************************************************************************
2020-08-05 11:06:19,483 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:06:19,492 p=5230 u=root |  changed: [k8-node]
2020-08-05 11:06:19,497 p=5230 u=root |  TASK [deploy_kubernetes : 6. Installing | br_netfilter | module] ********************************************************************
2020-08-05 11:06:19,514 p=5230 u=root |  skipping: [k8-master]
2020-08-05 11:06:19,521 p=5230 u=root |  skipping: [k8-node]
2020-08-05 11:06:19,526 p=5230 u=root |  TASK [deploy_kubernetes : 7. Setting bridged call iptables sysctl rules] ************************************************************
2020-08-05 11:06:20,003 p=5230 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 11:06:20,052 p=5230 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-ip6tables)
2020-08-05 11:06:20,351 p=5230 u=root |  ok: [k8-node] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 11:06:20,363 p=5230 u=root |  ok: [k8-master] => (item=net.bridge.bridge-nf-call-iptables)
2020-08-05 11:06:20,368 p=5230 u=root |  TASK [deploy_kubernetes : 8. Updating bridged iptable rules to kernel] **************************************************************
2020-08-05 11:06:20,739 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:06:20,755 p=5230 u=root |  changed: [k8-node]
2020-08-05 11:06:20,760 p=5230 u=root |  TASK [deploy_kubernetes : 9. Setting up required Kubernetes repository] *************************************************************
2020-08-05 11:06:21,344 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:06:21,365 p=5230 u=root |  ok: [k8-node]
2020-08-05 11:06:21,370 p=5230 u=root |  TASK [deploy_kubernetes : 9.x Deploying additional repository if OS is Redhat] ******************************************************
2020-08-05 11:06:21,969 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:06:21,983 p=5230 u=root |  ok: [k8-node]
2020-08-05 11:06:21,988 p=5230 u=root |  TASK [deploy_kubernetes : 10. Installing required | Kubernetes | packages] **********************************************************
2020-08-05 11:08:22,487 p=5230 u=root |  changed: [k8-node]
2020-08-05 11:08:25,421 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:08:25,445 p=5230 u=root |  TASK [deploy_kubernetes : 11. Starting |docker , kubelet| service] ******************************************************************
2020-08-05 11:08:28,217 p=5230 u=root |  changed: [k8-master] => (item=docker)
2020-08-05 11:08:28,268 p=5230 u=root |  changed: [k8-node] => (item=docker)
2020-08-05 11:08:29,107 p=5230 u=root |  changed: [k8-master] => (item=kubelet)
2020-08-05 11:08:29,159 p=5230 u=root |  changed: [k8-node] => (item=kubelet)
2020-08-05 11:08:29,164 p=5230 u=root |  TASK [deploy_kubernetes : 12. Check if Kubernetes has already been initialized.] ****************************************************
2020-08-05 11:08:29,521 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:08:29,533 p=5230 u=root |  ok: [k8-node]
2020-08-05 11:08:29,538 p=5230 u=root |  TASK [deploy_kubernetes : 13. [ ------------------------ | Master Setup | ----------------------] ***********************************
2020-08-05 11:08:29,565 p=5230 u=root |  skipping: [k8-node]
2020-08-05 11:08:29,582 p=5230 u=root |  included: /opt/python/ansible/kubernetesCluster/deploy_kubernetes/tasks/k8-master-setup.yml for k8-master
2020-08-05 11:08:29,591 p=5230 u=root |  TASK [deploy_kubernetes : 13.1. Kubernetes initialization on master] ****************************************************************
2020-08-05 11:12:57,449 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:12:57,455 p=5230 u=root |  TASK [deploy_kubernetes : 13.2. Creating requird directory structure] ***************************************************************
2020-08-05 11:12:57,941 p=5230 u=root |  changed: [k8-master] => (item=mkdir -p ~/.kube)
2020-08-05 11:12:58,398 p=5230 u=root |  changed: [k8-master] => (item=sudo cp -i /etc/kubernetes/admin.conf ~/.kube/config)
2020-08-05 11:12:58,868 p=5230 u=root |  changed: [k8-master] => (item=sudo chown $(id -u):$(id -g) ~/.kube/config)
2020-08-05 11:12:58,870 p=5230 u=root |   [WARNING]: Consider using file module with state=directory rather than running mkdir

2020-08-05 11:12:58,870 p=5230 u=root |   [WARNING]: Consider using 'become', 'become_method', and 'become_user' rather than running sudo

2020-08-05 11:12:58,876 p=5230 u=root |  TASK [deploy_kubernetes : 13.3. Generate join command] ******************************************************************************
2020-08-05 11:12:59,325 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:12:59,350 p=5230 u=root |  TASK [deploy_kubernetes : 13.4. Setting up the command use globally] ****************************************************************
2020-08-05 11:12:59,414 p=5230 u=root |  ok: [k8-master]
2020-08-05 11:12:59,419 p=5230 u=root |  TASK [deploy_kubernetes : 14. [ ------------------------ | Nodes/Worker Setup | ----------------] ***********************************
2020-08-05 11:12:59,437 p=5230 u=root |  skipping: [k8-master]
2020-08-05 11:12:59,459 p=5230 u=root |  included: /opt/python/ansible/kubernetesCluster/deploy_kubernetes/tasks/k8-worker-setup.yml for k8-node
2020-08-05 11:12:59,472 p=5230 u=root |  TASK [deploy_kubernetes : 14.1 Joining Worker to | Kubernetes | cluster] ************************************************************
2020-08-05 11:13:15,371 p=5230 u=root |  changed: [k8-node] => (item=k8-master)
2020-08-05 11:13:15,377 p=5230 u=root |  TASK [deploy_kubernetes : 15. Ending with role deployment] **************************************************************************
2020-08-05 11:13:15,468 p=5230 u=root |  ok: [k8-master] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-08-05 11:13:15,481 p=5230 u=root |  ok: [k8-node] => {
    "msg": "Kuberenetes deployment ended ... "
}
2020-08-05 11:13:15,487 p=5230 u=root |  TASK [Post-Requisite Configuring | weave | network] *********************************************************************************
2020-08-05 11:13:15,515 p=5230 u=root |  skipping: [k8-node]
2020-08-05 11:13:20,527 p=5230 u=root |  changed: [k8-master]
2020-08-05 11:13:20,529 p=5230 u=root |  PLAY RECAP **************************************************************************************************************************
2020-08-05 11:13:20,529 p=5230 u=root |  k8-master                  : ok=21   changed=9    unreachable=0    failed=0   
2020-08-05 11:13:20,529 p=5230 u=root |  k8-node                    : ok=17   changed=6    unreachable=0    failed=0   
